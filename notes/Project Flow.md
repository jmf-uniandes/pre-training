# üìòConfiguraci√≥n y Flujo de Trabajo ‚Äì An√°lisis Musical con Python ‚Äì

**Proyecto:** An√°lisis de Atributos Musicales y Predicci√≥n de Popularidad de Canciones  

![Arquitectura](img/arquitectura.png "1. Arquitectura")

![Entregable](img/entregable-final.png "2. Entregable final")

![Plan](img/plan-proyecto-inicial.png "3. Plan del Proyecto")



## 1. Importar las librer√≠as

Las siguientes librer√≠as son las que se utilizan normalmente en el manejo, an√°lisis y visualizaci√≥n de datos.  

```python
# Parte 1
# Manipulaci√≥n de datos con DataFrames.
import pandas as pd

# Operaciones num√©ricas y manejo de arrays.
import numpy as np

# Creaci√≥n de gr√°ficos b√°sicos (l√≠neas, barras, histogramas, etc.).
import matplotlib.pyplot as plt

# Visualizaci√≥n estad√≠stica avanzada (mapas de calor, distribuciones).
import seaborn as sns

# Modelado y algoritmos de aprendizaje autom√°tico.
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Modelos avanzados de boosting.
import xgboost as xgb
import lightgbm as lgb

# Detecci√≥n y visualizaci√≥n de datos nulos.
import missingno as msno

# Gr√°ficos interactivos para dashboards.
import plotly.express as px
import plotly.graph_objects as go

# Librer√≠as adicionales para entorno Jupyter y manejo interactivo.
from IPython.display import display, HTML
```
---
**Descripci√≥n breve de librer√≠as utilizadas:**

- **pandas**: lectura, limpieza y manipulaci√≥n de datos tabulares.  
- **numpy**: operaciones matem√°ticas y manejo de vectores o matrices.  
- **matplotlib**: gr√°ficos de l√≠neas, barras, histogramas, etc.  
- **seaborn**: visualizaciones estad√≠sticas (mapas de calor, distribuciones).  
- **scikit-learn**: modelado y algoritmos de aprendizaje autom√°tico.  
- **missingno**: detecci√≥n y visualizaci√≥n de datos nulos.  
- **plotly**: gr√°ficos interactivos para dashboards.  
- **jupyter**: entorno interactivo para desarrollo y an√°lisis. 
- **xgboost**:	Implementaci√≥n optimizada del algoritmo de Extreme Gradient Boosting (XGBoost).
- **lightgbm**:	Algoritmo de Gradient Boosting r√°pido y eficiente desarrollado por Microsoft. 

---

## 2. Configuraci√≥n del Entorno Virtual y Desarrollo del Proyecto

Para aislar las dependencias del proyecto y mantener versiones estables.

```bash
# Paso 1: Crear entorno virtual, v3.13 es la maxima compatible con streamlit
py -3.13 -m venv .venv 

# Paso 2: Activar entorno virtual
.venv\Scripts\activate

#Paso 2a seleccionar interprete de python para el entorno virtual
a) Presionar Ctrl + shift + P
b) Click en Pyhton: Select Interpreter
c) Seleccionar el que tenga el entorno virtual. Pyhton 3.13.19(.venv) .\.venv\Scripts\python.exe

# Instalar Jupyter  para visualizar resultado de los archivos de jupyter
pip install jupyter ipykernel

# Paso 3: Instalar librer√≠as necesarias y actualizar pip a su nueva version
pip install pandas numpy matplotlib seaborn tabulate

python.exe -m pip install --upgrade pip

pip install scikit-learn missingno plotly streamlit lightgbm xgboost

# Paso 4: Exportar dependencias instaladas, despues se puede usar el comando pip install -r requirements.txt

pip freeze > requirements.txt

# Paso 5: Clonar el repositorio del proyecto
 (Repositorio documentado en 'Github_notes.md')

# Paso 6: Realizar las actividades asignadas y creacion del modelo.

# Paso 7: Creacion del API con FastAPI
pip install fastapi "uvicorn[standard]" pydantic

# Paso 8: Pruebas de la API en entorno virtual
# http://127.0.0.1:8000/docs
uvicorn src.api.main:app --reload

# Paso 9: Creacion de requirements_api.txt para que docker use los requisit
pip freeze > requirements_api.txt

# Paso 9: Creacion y prueba del Dashboard con Streamlit
pip install streamlit plotly
streamlit run app.py

# Paso 10: Creacion del archivo requirements.txt para la publicaci√≥n del Dashboard. 
pip freeze > requirements_api.txt

```

Comentarios:
- `.venv` crea un entorno virtual local.  
- `pip freeze` genera un archivo con versiones exactas de librer√≠as.(crear una para Docker, una para API y una general)  
- `requirementsApp.txt` permite replicar el entorno en otro equipo f√°cilmente.  
- `requirements_api.txt` permite replicar el entorno con Docker.  
- `requirements.txt` permite realizar la publicaci√≥n en Streamlite Cloud.  

---

## 3. Flujo del Proyecto (Flow Project)

Este flujo organiza las etapas principales del an√°lisis y modelado.

1. Carga de los datos (dataset).  
2. An√°lisis Exploratorio de los Datos (EDA).  
3. Preparaci√≥n y tratamiento previo de los datos.  
4. Visualizaci√≥n gr√°fica de los datos.  
5. Generaci√≥n de los modelos de aprendizaje autom√°tico.  
6. Entrenamiento del los modelos de aprendizaje autom√°tico.  
7. Definici√≥n final del modelo predictivo y entrenamiento.  
8. Evaluaci√≥n del modelo entrenado con datos reservados.
9. Creacion del modelo joblib
10. Creacion de la API, mediante Fast API
11. Prueba local y publicaci√≥n
12. Creaci√≥n y prueba del Dashboard usando Streamlit
13. Publicaci√≥n del Dashboard

### Ejemplos de comandos en EDA

```python
# Vista inicial del dataset
data.head()

# Dimensiones del set de datos
print("Tama√±o del set de datos:", data.shape)

# Informaci√≥n general del dataset
data.info()

# Conteo de valores nulos
data.isnull().sum()

# Conteo de registros duplicados
data.duplicated().sum()
```

Comentarios:
- `data.head()` muestra las primeras filas para verificar estructura.  
- `data.shape` indica cu√°ntas filas y columnas contiene.  
- `data.info()` ayuda a detectar tipos de datos y nulos.  
- `isnull()` y `duplicated()` permiten identificar problemas de calidad.  

### Limpieza de Datos (duplicados y nulos)

```python
# Identificar registros duplicados
duplicated_rows = data[data.duplicated()]
print(duplicated_rows)

# Eliminar filas duplicadas
print("Tama√±o antes:", data.shape)
data.drop_duplicates(inplace=True)
print("Tama√±o despu√©s:", data.shape)

# Identificar valores nulos en la columna 'Artist'
null_artists = data[data['Artist'].isnull()]
print("\n√çndices con artistas nulos:")
print(null_artists.index.tolist())

# Eliminar filas con artistas nulos
print("Nulos antes:", data['Artist'].isnull().sum())
data.dropna(subset=['Artist'], inplace=True)
print("Nulos despu√©s:", data['Artist'].isnull().sum())
```
Comentarios:
- `data.duplicated()` localiza registros repetidos.  
- `drop_duplicates()` elimina duplicados sin crear una nueva copia.  
- `dropna()` elimina filas con valores faltantes en columnas clave.  

---
### Tipos de valores faltantes en Python y pandas

#### **NaN ‚Äî Not a Number**
Valor especial del tipo `float`, proveniente de NumPy, utilizado para representar **datos faltantes num√©ricos**.

**Caracter√≠sticas:**
- Tipo: `float`
- `NaN != NaN`
- Propaga en operaciones matem√°ticas
- Se usa en columnas num√©ricas

**Ejemplo:**
```python
import numpy as np

x = np.nan
print(type(x))      # float
print(x == x)       # False
```

---

#### **None ‚Äî Valor nulo en Python (similar a NULL)**
Representa ausencia de valor en Python.

**Caracter√≠sticas:**
- Tipo: `NoneType`
- No se puede usar en operaciones matem√°ticas
- Com√∫n en columnas tipo `object` (texto)

**Ejemplo:**
```python
x = None
print(type(x))      # NoneType
```

---

## Uso interno en Pandas

| Tipo de columna | Valor faltante usado |
|----------------|----------------------|
| Num√©ricas      | `NaN`                |
| Strings/Objetos | `None` o `pd.NA`     |
| Tipos extendidos (Int64, boolean, string) | `pd.NA` |

---
## 4. Estructura General del Proyecto, EDA, API, Dashboard

**Estructura del Proyecto**

```
CASE-STUDY-SPOTIFY/
PRE-TRAINING/
‚îÇ
‚îú‚îÄ‚îÄ .streamlit/
‚îÇ   ‚îî‚îÄ‚îÄ config.toml
‚îÇ
‚îú‚îÄ‚îÄ .venv/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SpotifyFeatures.csv
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spotify_clean_modeling.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spotify_clean.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ X_test.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ y_test.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ y_pred_model_evaluation.csv
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ processed/extra/ (si deseas mantener otras versiones)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_loader.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_eda.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_model_trainingold.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 05_model_evaluation.ipynb
‚îÇ
‚îú‚îÄ‚îÄ notes/
‚îÇ   ‚îú‚îÄ‚îÄ img/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ img-samples-dashboard/
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Github_notes.md
‚îÇ   ‚îú‚îÄ‚îÄ Json_API_test.json
‚îÇ   ‚îú‚îÄ‚îÄ Markdown_info.md
‚îÇ   ‚îú‚îÄ‚îÄ Project Flow.md
‚îÇ   ‚îî‚îÄ‚îÄ Spotify_Dataset_Description.md
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_pipeline.joblib
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocess.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ static/   (Cuando la API sirve archivos est√°ticos, ej. Icono)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements_api.txt      (Usando para crear imagen de Docker)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ custom.css
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1_metrics.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gauge.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ __pycache__/   (ignorado en producci√≥n)
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îÇ
‚îú‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt         (para Streamlit)
‚îî‚îÄ‚îÄ requirementsApp.txt      (para entorno general)

```

---
## 5. Enfoque del An√°lisis Exploratorio EDA

Durante el EDA, se analizan principalmente:
- Datos nulos.  
- Registros duplicados.  
- Valores vac√≠os o inconsistentes.  
- Distribuciones estad√≠sticas de cada atributo (por ejemplo, energy, danceability, valence).  

Estos pasos aseguran una base de datos limpia antes del modelado.  

---
## 5.1. Mejores Pr√°cticas

- **processed/**: evita modificar los datos originales; lugar donde se guardan los datasets limpios.  
- **utils/**: concentra funciones comunes, como carga de datos, limpieza o visualizaci√≥n.  
- **api/**: Core para la creaci√≥n del API con todos sus endpoint(s) `/songs/predict_hit`.  
- **dashboard/**: Core para la creaci√≥n de la visualizaci√≥n Front-End de la app.  
---


# 5.2. Modelos que podrian usarse para (clasificaci√≥n ‚Äúhit / no hit‚Äù)

| Tipo                    | Modelos                                                               | Prop√≥sito en tu experimento                        |
|--------------------------|-----------------------------------------------------------------------|----------------------------------------------------|
| **√Årboles y Ensambles** | RandomForestClassifier, GradientBoostingClassifier, XGBoost, LightGBM | Modelos potentes, capturan relaciones no lineales. |
| **Lineal**              | LogisticRegression                                                    | Baseline interpretable.                            |
| **Distancia**           | KNeighborsClassifier                                                  | Comparativo, sensible al escalado.                 |

---

| Modelo                   | Librer√≠a              | Composici√≥n           | Cu√°ndo usarlo                                      | Conversi√≥n de `genre` |
|---------------------------|----------------------|-----------------------|----------------------------------------------------|------------------------|
| **RandomForestClassifier**     | `sklearn.ensemble`    | Ensemble (√°rboles)     | Base s√≥lida, robusto sin escalar.                  | `LabelEncoder` |
| **GradientBoostingClassifier** | `sklearn.ensemble`    | Ensemble (boosting)    | M√°s preciso, controla bien el overfitting (sobreajuste extremo).         | `LabelEncoder` |
| **XGBClassifier**              | `xgboost`             | Boosting avanzado      | Precisi√≥n alta, r√°pido.                            | `LabelEncoder` |
| **LGBMClassifier**             | `lightgbm`            | Boosting optimizado    | Muy r√°pido en datasets grandes.                    | `LabelEncoder` |
| **LogisticRegression**         | `sklearn.linear_model` | Lineal                 | Buen baseline interpretativo.                      | `OneHotEncoder` |
| **KNeighborsClassifier**       | `sklearn.neighbors`   | Distancia              | Comparativo; sensible al escalado.                 | `OneHotEncoder` |




| Modelo               | Ajuste aplicado              | Efecto                                                  |
| -------------------- | ---------------------------- | ------------------------------------------------------- |
| `RandomForest`       | `class_weight='balanced'`    | Aumenta la importancia de los hits (clase minoritaria). |
| `GradientBoosting`   | sin soporte directo          | Se deja igual, o puedes balancear por resampling.       |
| `XGBoost`            | `scale_pos_weight=ratio`     | Corrige el desbalance en la funci√≥n de p√©rdida.         |
| `LightGBM`           | `class_weight='balanced'`    | Pondera internamente las clases.                        |
| `LogisticRegression` | `class_weight='balanced'`    | Ajusta los pesos durante la optimizaci√≥n.               |
| `KNeighbors`         | no soporta pesos autom√°ticos | Se mantiene igual.                                      |


El dataset tiene solo 4.53 % de canciones ‚Äúhit‚Äù, lo que provoca que los modelos prioricen predecir ‚Äúno-hit‚Äù (clase 0).
Con class_weight='balanced' y scale_pos_weight, cada modelo penaliza m√°s los errores en la clase minoritaria, mejorando recall y F1-score.


### 5.3. An√°lisis de Resultados

| Modelo                  | Accuracy | F1-Score (Hit) | ROC AUC | Conclusiones                                                                                   |
|-------------------------|----------|----------------|---------|------------------------------------------------------------------------------------------------|
| **LightGBM**            | 0.929552 | 0.531505       | 0.891965 | Mejor desempe√±o del batch. Alto poder de discriminaci√≥n y mejor F1 en detecci√≥n de Hits.        |
| **XGBoost**             | 0.926609 | 0.523438       | 0.893899 | Muy s√≥lido y cercano a LightGBM. Excelente AUC y buen equilibrio entre precisi√≥n y recall.      |
| **Logistic Regression** | 0.777828 | 0.263829       | 0.810842 | Interpretaci√≥n sencilla, pero limitada para capturar patrones complejos del dataset.            |
| **Random Forest**       | 0.755720 | 0.244518       | 0.796417 | Modelo estable pero sesgado hacia la clase mayoritaria (No-Hit).                                |
| **Gradient Boosting**   | 0.955892 | 0.143513       | 0.538895 | Accuracy enga√±osamente alto; falla en identificar Hits.                                         |
| **K-Neighbors**         | 0.953378 | 0.020758       | 0.505191 | Muy mal F1 para Hits. Predomina completamente la clase No-Hit.                                  |

---

### üèÅ Conclusi√≥n final

- **LightGBM** ‚Üí es el modelo √≥ptimo para el step 4 `04_model_training.ipynb`.  
- **XGBoost** ‚Üí referencia secundaria para comparar despu√©s del ajuste de hiperpar√°metros.

---

### 5.4. üìä M√©tricas utilizadas
Debido al dataset desbalanceado (4.6% hits), no es suficiente usar solo accuracy.
Por eso se evaluar√°n 3 m√©tricas clave y una adicional al validar el modelo. Matriz de confusi√≥n.

- **accuracy_score** ‚Üí mide qu√© proporci√≥n de predicciones fueron correctas.  
- **f1_score** ‚Üí mide el equilibrio entre *precisi√≥n* y *recall* (√∫til si las clases est√°n desbalanceadas).  
- **roc_auc_score** ‚Üí mide la capacidad del modelo para distinguir entre clases (cuanto m√°s cerca de 1, mejor).

**Notes**
1. Accuracy
No es muy √∫til con un desbalance (un modelo que prediga ‚Äútodo es no-hit‚Äù ya logra 95%).

2. F1-score
Es la m√©trica cr√≠tica cuando la clase ‚Äúhit‚Äù es muy minoritaria.
Eval√∫a qu√© tan bien detecta hits sin generar demasiados falsos positivos.

3. ROC-AUC
No depende del umbral por defecto de 0.5.
Valores:
0.5 = aleatorio
1.0 = perfecto (un buen modelo suele estar > 0.80).


### 5.5 üïµÔ∏è Modelos a evaluar 

1. Logistic Regression

Modelo lineal.
Sirve como baseline. R√°pido, interpretable y muestra qu√© variables empujan a la probabilidad de ser hit.

2. Random Forest

Ensamble de muchos √°rboles de decisi√≥n.
Robusto, maneja no-linealidades y detecta interacciones entre features autom√°ticamente.

3. Gradient Boosting (GBM cl√°sico de sklearn)

Construye √°rboles de manera secuencial, corrigiendo errores del anterior.
Mejor rendimiento que RandomForest pero m√°s lento.

4. XGBoost

Implementaci√≥n optimizada y m√°s poderosa de boosting.
Alta precisi√≥n, muy usado en competencias de Kaggle. Excelente con datasets tabulares.

5. LightGBM

Boosting muy r√°pido desarrollado por Microsoft.
Funciona excelente con grandes vol√∫menes (como tu dataset de 230k filas).
Suele superar a XGBoost en velocidad con rendimiento similar o mejor.

M√©tricas que se van a comparar

### 5.6 Resumen EDA
Entrenaremos 5 algoritmos (lineales, √°rboles y boostings) y los compararemos usando m√©tricas robustas frente al desbalance (F1 y AUC) para seleccionar el mejor modelo que predice si una canci√≥n puede ser un hit.


### 6. Resumen Final Entregables

**Estructura Final SRC**

- API FastAPI ‚Üí carpeta src/api/
- Modelo entrenado ‚Üí carpeta src/api/models
- Dashboard Streamlit ‚Üí carpeta src/dashboard/


**Publicaci√≥n** 

```
                 +------------------------+
                 |   Streamlit Cloud      |
                 |   (Dashboard UI)       |
                 |   https://...app       |
                 +-----------+------------+
                             |
                             |  HTTPS (POST/JSON)
                             v
         +---------------------------------------------+
         |  Railway.app (API FastAPI + Modelo ML)      |
         |  https://<project>.railway.app/predict_hit   |
         +---------------------------------------------+

Dashboard ‚Üí Streamlit Cloud (sin Docker)
API FastAPI ‚Üí Railway (con Docker obligatorio)
```
