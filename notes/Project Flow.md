# üìòGu√≠a de Configuraci√≥n y Flujo de Trabajo ‚Äì An√°lisis Musical con Python
**Proyecto:** An√°lisis de Atributos Musicales y Predicci√≥n de Popularidad de Canciones  

![Arquitectura](img/arquitectura.png "1. Arquitectura")

![Entregable](img/entregable-final.png "2. Entregable final")

![Plan](img/plan-proyecto-inicial.png "3. Plan del Proyecto")



## 1. Importar las librer√≠as

Las siguientes librer√≠as son las que se utilizan normalmente en el manejo, an√°lisis y visualizaci√≥n de datos.  

```python
# Parte 1
# Manipulaci√≥n de datos con DataFrames.
import pandas as pd

# Operaciones num√©ricas y manejo de arrays.
import numpy as np

# Creaci√≥n de gr√°ficos b√°sicos (l√≠neas, barras, histogramas, etc.).
import matplotlib.pyplot as plt

# Visualizaci√≥n estad√≠stica avanzada (mapas de calor, distribuciones).
import seaborn as sns




# Modelado y algoritmos de aprendizaje autom√°tico.
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Modelos avanzados de boosting.
import xgboost as xgb
import lightgbm as lgb

# Detecci√≥n y visualizaci√≥n de datos nulos.
import missingno as msno

# Gr√°ficos interactivos para dashboards.
import plotly.express as px
import plotly.graph_objects as go

# Librer√≠as adicionales para entorno Jupyter y manejo interactivo.
from IPython.display import display, HTML
```

**Descripci√≥n breve de librer√≠as utilizadas:**
- **pandas**: lectura, limpieza y manipulaci√≥n de datos tabulares.  
- **numpy**: operaciones matem√°ticas y manejo de vectores o matrices.  
- **matplotlib**: gr√°ficos de l√≠neas, barras, histogramas, etc.  
- **seaborn**: visualizaciones estad√≠sticas (mapas de calor, distribuciones).  
- **scikit-learn**: modelado y algoritmos de aprendizaje autom√°tico.  
- **missingno**: detecci√≥n y visualizaci√≥n de datos nulos.  
- **plotly**: gr√°ficos interactivos para dashboards.  
- **jupyter**: entorno interactivo para desarrollo y an√°lisis. 
- **xgboost**:	Implementaci√≥n optimizada del algoritmo de Extreme Gradient Boosting (XGBoost).
- **lightgbm**:	Algoritmo de Gradient Boosting r√°pido y eficiente desarrollado por Microsoft. 

---

## 2. Configuraci√≥n del Entorno Virtual

Para aislar las dependencias del proyecto y mantener versiones estables.

```bash
# Paso 1: Crear entorno virtual, v3.13 es la maxima compatible con streamlit
py -3.13 -m venv .venv 

# Paso 2: Activar entorno virtual
.venv\Scripts\activate

#Paso 2a seleccionar interprete de python para el entorno virtual
a) Presionar Ctrl + shift + P
b) Click en Pyhton: Select Interpreter
c) Seleccionar el que tenga el entorno virtual, ej.  Pyhton 3.13.19(.venv) .\.venv\Scripts\python.exe

# Instalar Jupyter  para visualizar resultado de los archivos de jupyter
pip install jupyter ipykernel

# Paso 3: Instalar librer√≠as necesarias y actualizar pip a su nueva version
pip install pandas numpy matplotlib seaborn tabulate

python.exe -m pip install --upgrade pip

pip install scikit-learn missingno plotly streamlit lightgbm xgboost


# Paso 4: Exportar dependencias instaladas, despues se puede usar el comando pip install -r requirements.txt

pip freeze > requirements.txt

# Paso 5: Clonar el repositorio del proyecto
# (Repositorio documentado en 'Github_notes.md')

# Paso 6: Realizar las actividades asignadas

#pip install fastapi "uvicorn[standard]" pydantic
#API
pip install fastapi "uvicorn[standard]" 

#Dashboard
pip install streamlit plotly




#http://127.0.0.1:8000/docs
```

Comentarios:
- `.venv` crea un entorno virtual local.  
- `pip freeze` genera un archivo con versiones exactas de librer√≠as.  
- `requirements.txt` permite replicar el entorno en otro equipo f√°cilmente.  

---

## 3. Flujo del Proyecto (Flow Project)

Este flujo organiza las etapas principales del an√°lisis y modelado.

1. Carga de los datos (dataset).  
2. An√°lisis Exploratorio de los Datos (EDA).  
3. Preparaci√≥n y tratamiento previo de los datos.  
4. Visualizaci√≥n gr√°fica de los datos.  
5. Generaci√≥n del modelo de aprendizaje autom√°tico.  
6. Entrenamiento del modelo de aprendizaje autom√°tico.  
7. Definici√≥n del modelo predictivo.  
8. Evaluaci√≥n del modelo entrenado con datos reservados.  

### Ejemplos de comandos en EDA

```python
# Vista inicial del dataset
data.head()

# Dimensiones del set de datos
print("Tama√±o del set de datos:", data.shape)

# Informaci√≥n general del dataset
data.info()

# Conteo de valores nulos
data.isnull().sum()

# Conteo de registros duplicados
data.duplicated().sum()
```

Comentarios:
- `data.head()` muestra las primeras filas para verificar estructura.  
- `data.shape` indica cu√°ntas filas y columnas contiene.  
- `data.info()` ayuda a detectar tipos de datos y nulos.  
- `isnull()` y `duplicated()` permiten identificar problemas de calidad.  

### Limpieza de Datos (duplicados y nulos)

```python
# Identificar registros duplicados
duplicated_rows = data[data.duplicated()]
print(duplicated_rows)

# Eliminar filas duplicadas
print("Tama√±o antes:", data.shape)
data.drop_duplicates(inplace=True)
print("Tama√±o despu√©s:", data.shape)

# Identificar valores nulos en la columna 'Artist'
null_artists = data[data['Artist'].isnull()]
print("\n√çndices con artistas nulos:")
print(null_artists.index.tolist())

# Eliminar filas con artistas nulos
print("Nulos antes:", data['Artist'].isnull().sum())
data.dropna(subset=['Artist'], inplace=True)
print("Nulos despu√©s:", data['Artist'].isnull().sum())
```

Comentarios:
- `data.duplicated()` localiza registros repetidos.  
- `drop_duplicates()` elimina duplicados sin crear una nueva copia.  
- `dropna()` elimina filas con valores faltantes en columnas clave.  

---

## 4. Enfoque del An√°lisis Exploratorio

Durante el EDA, se analizan principalmente:
- Datos nulos.  
- Registros duplicados.  
- Valores vac√≠os o inconsistentes.  
- Distribuciones estad√≠sticas de cada atributo (por ejemplo, energy, danceability, valence).  

Estos pasos aseguran una base de datos limpia antes del modelado.  

---

# Estructura del Proyecto

```
CASE-STUDY-SPOTIFY/
‚îÇ
‚îú‚îÄ‚îÄ data/                     
‚îÇ   ‚îú‚îÄ‚îÄ raw/                  # Datos originales intactos y limpios
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SpotifyFeatures.csv
‚îÇ   ‚îú‚îÄ‚îÄ processed/            
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ spotify_clean.csv
‚îÇ
‚îú‚îÄ‚îÄ models/                   
‚îÇ   ‚îú‚îÄ‚îÄ random_forest.pkl
‚îÇ   ‚îú‚îÄ‚îÄ xgboost_model.json
‚îÇ   ‚îú‚îÄ‚îÄ lightgbm_model.txt
‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl            # Escalador o encoder
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                
‚îÇ   ‚îú‚îÄ‚îÄ 01_loader.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_eda.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_model_training.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 05_evaluation.ipynb
‚îÇ
‚îú‚îÄ‚îÄ notes/                    
‚îÇ   ‚îú‚îÄ‚îÄ img/
‚îÇ   ‚îú‚îÄ‚îÄ Github_notes.md
‚îÇ   ‚îú‚îÄ‚îÄ Markdown_info.md
‚îÇ   ‚îú‚îÄ‚îÄ Project Flow.md
‚îÇ   ‚îî‚îÄ‚îÄ References.md         # Bibliograf√≠a y links √∫tiles
‚îÇ
‚îú‚îÄ‚îÄ src/                      
‚îÇ   ‚îú‚îÄ‚îÄ utils/                
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py       # Importaciones como m√≥dulo Python
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ visualizations.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_utils.py
‚îÇ   ‚îú‚îÄ‚îÄ api/                  
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_service.py  # Funci√≥n predictiva central (load_model + predict)
‚îÇ   ‚îî‚îÄ‚îÄ dashboard/            # Streamlit app
‚îÇ       ‚îî‚îÄ‚îÄ buscador_de_hits.py
‚îÇ
‚îú‚îÄ‚îÄ results/                  
‚îÇ   ‚îú‚îÄ‚îÄ figures/              
‚îÇ   ‚îú‚îÄ‚îÄ metrics/              
‚îÇ   ‚îî‚îÄ‚îÄ reports/              # PDF o notebooks convertidos a HTML/PDF
‚îÇ
‚îú‚îÄ‚îÄ tests/                    
‚îÇ   ‚îú‚îÄ‚îÄ test_data_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ test_model.py
‚îÇ   ‚îî‚îÄ‚îÄ test_api.py
‚îÇ
‚îú‚îÄ‚îÄ main.py                   
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ setup.md                  
‚îî‚îÄ‚îÄ environment.yml            # entorno reproducible (conda o venv) Docker

```

---

## Recomendaciones

- **processed/**: evita modificar los datos originales; guarda aqu√≠ los datasets limpios.  
- **results/**: √∫til para almacenar gr√°ficas, m√©tricas y comparaciones entre modelos.  
- **utils/**: concentra funciones comunes, como carga de datos, limpieza o visualizaci√≥n.  
- **api/**: te servir√° cuando implementes el endpoint `/songs/predict_hit`.  
- **tests/**: si piensas escalar el proyecto o evaluarlo acad√©micamente, esto muestra buenas pr√°cticas.  

---


# Modelos exactos recomendados (clasificaci√≥n ‚Äúhit / no hit‚Äù)

| Tipo                    | Modelos                                                               | Prop√≥sito en tu experimento                        |
|--------------------------|-----------------------------------------------------------------------|----------------------------------------------------|
| **√Årboles y Ensambles** | RandomForestClassifier, GradientBoostingClassifier, XGBoost, LightGBM | Modelos potentes, capturan relaciones no lineales. |
| **Lineal**              | LogisticRegression                                                    | Baseline interpretable.                            |
| **Distancia**           | KNeighborsClassifier                                                  | Comparativo, sensible al escalado.                 |

---

| Modelo                   | Librer√≠a              | Composici√≥n           | Cu√°ndo usarlo                                      | Conversi√≥n de `genre` |
|---------------------------|----------------------|-----------------------|----------------------------------------------------|------------------------|
| **RandomForestClassifier**     | `sklearn.ensemble`    | Ensemble (√°rboles)     | Base s√≥lida, robusto sin escalar.                  | `LabelEncoder` |
| **GradientBoostingClassifier** | `sklearn.ensemble`    | Ensemble (boosting)    | M√°s preciso, controla bien el overfitting.         | `LabelEncoder` |
| **XGBClassifier**              | `xgboost`             | Boosting avanzado      | Precisi√≥n alta, r√°pido.                            | `LabelEncoder` |
| **LGBMClassifier**             | `lightgbm`            | Boosting optimizado    | Muy r√°pido en datasets grandes.                    | `LabelEncoder` |
| **LogisticRegression**         | `sklearn.linear_model` | Lineal                 | Buen baseline interpretativo.                      | `OneHotEncoder` |
| **KNeighborsClassifier**       | `sklearn.neighbors`   | Distancia              | Comparativo; sensible al escalado.                 | `OneHotEncoder` |




| Modelo               | Ajuste aplicado              | Efecto                                                  |
| -------------------- | ---------------------------- | ------------------------------------------------------- |
| `RandomForest`       | `class_weight='balanced'`    | Aumenta la importancia de los hits (clase minoritaria). |
| `GradientBoosting`   | sin soporte directo          | Se deja igual, o puedes balancear por resampling.       |
| `XGBoost`            | `scale_pos_weight=ratio`     | Corrige el desbalance en la funci√≥n de p√©rdida.         |
| `LightGBM`           | `class_weight='balanced'`    | Pondera internamente las clases.                        |
| `LogisticRegression` | `class_weight='balanced'`    | Ajusta los pesos durante la optimizaci√≥n.               |
| `KNeighbors`         | no soporta pesos autom√°ticos | Se mantiene igual.                                      |


Tu dataset tiene solo 4.53 % de canciones ‚Äúhit‚Äù, lo que provoca que los modelos prioricen predecir ‚Äúno-hit‚Äù (clase 0).
Con class_weight='balanced' y scale_pos_weight, cada modelo penaliza m√°s los errores en la clase minoritaria, mejorando recall y F1-score.


### Analisis de Resultado

| Modelo                  | Accuracy | F1-Score (Hit) | ROC AUC | Conclusiones                                                                                                                   |
| ----------------------- | -------- | -------------- | ------- | ------------------------------------------------------------------------------------------------------------------------------ |
| **LightGBM**            | 0.8937   | 0.4439         | 0.8785  | Mejor desempe√±o general. Mantiene alto poder de discriminaci√≥n y el F1 m√°s equilibrado. Ideal para continuar el entrenamiento. |
| **XGBoost**             | 0.8856   | 0.4262         | 0.8740  | Muy competitivo, pero ligeramente inferior a LightGBM en Recall y estabilidad.                                                 |
| **Random Forest**       | 0.8576   | 0.2837         | 0.6986  | Consistente pero sesgado hacia la clase No-Hit.                                                                                |
| **Logistic Regression** | 0.7779   | 0.2646         | 0.8122  | Base lineal razonable, pero limitada para capturar relaciones complejas.                                                       |
| **Gradient Boosting**   | 0.9554   | 0.1321         | 0.5356  | Accuracy inflado; pobre desempe√±o en detecci√≥n de Hits.                                                                        |
| **K-Neighbors**         | 0.9520   | 0.0809         | 0.5214  | Alto Accuracy por sesgo hacia No-Hit. Ineficiente para identificar Hits.                                                       |

---

### üèÅ Conclusi√≥n final

- **LightGBM** ‚Üí modelo √≥ptimo para pasar al archivo `04_model_training.ipynb`.  
- **XGBoost** ‚Üí referencia secundaria para comparar despu√©s del ajuste de hiperpar√°metros.

---

### üìä M√©tricas utilizadas

- **accuracy_score** ‚Üí mide qu√© proporci√≥n de predicciones fueron correctas.  
- **f1_score** ‚Üí mide el equilibrio entre *precisi√≥n* y *recall* (√∫til si las clases est√°n desbalanceadas).  
- **roc_auc_score** ‚Üí mide la capacidad del modelo para distinguir entre clases (cuanto m√°s cerca de 1, mejor).


1. Logistic Regression

Modelo lineal.
Sirve como baseline. R√°pido, interpretable y muestra qu√© variables empujan a la probabilidad de ser hit.

2. Random Forest

Ensamble de muchos √°rboles de decisi√≥n.
Robusto, maneja no-linealidades y detecta interacciones entre features autom√°ticamente.

3. Gradient Boosting (GBM cl√°sico de sklearn)

Construye √°rboles de manera secuencial, corrigiendo errores del anterior.
Mejor rendimiento que RandomForest pero m√°s lento.

4. XGBoost

Implementaci√≥n optimizada y m√°s poderosa de boosting.
Alta precisi√≥n, muy usado en competencias de Kaggle. Excelente con datasets tabulares.

5. LightGBM

Boosting muy r√°pido desarrollado por Microsoft.
Funciona excelente con grandes vol√∫menes (como tu dataset de 230k filas).
Suele superar a XGBoost en velocidad con rendimiento similar o mejor.

M√©tricas que se van a comparar

Debido al dataset desbalanceado (4.6% hits), no sirve usar solo accuracy.
Por eso se eval√∫an 3 m√©tricas clave:

1. Accuracy

Porcentaje de predicciones correctas.
No es muy √∫til con desbalance (un modelo que prediga ‚Äútodo es no-hit‚Äù ya logra 95%).

2. F1-score

Promedio entre precision y recall para la clase positiva (hit).
Es la m√©trica cr√≠tica cuando la clase ‚Äúhit‚Äù es muy minoritaria.
Eval√∫a qu√© tan bien detecta hits sin generar demasiados falsos positivos.

3. ROC-AUC

Mide la capacidad del modelo de separar ambas clases.
No depende del umbral 0.5.
Valores:

0.5 = aleatorio

1.0 = perfecto
Un buen modelo suele estar > 0.80

En una frase:

Entrenaremos 5 algoritmos (lineales, √°rboles y boostings) y los compararemos usando m√©tricas robustas frente al desbalance (F1 y AUC) para seleccionar el mejor modelo que predice si una canci√≥n puede ser un hit.