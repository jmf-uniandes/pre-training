# ðŸ“˜GuÃ­a de ConfiguraciÃ³n y Flujo de Trabajo â€“ AnÃ¡lisis Musical con Python
**Proyecto:** AnÃ¡lisis de Atributos Musicales y PredicciÃ³n de Popularidad de Canciones  

![Arquitectura](img/arquitectura.png "1. Arquitectura")

![Entregable](img/entregable-final.png "2. Entregable final")

![Plan](img/plan-proyecto-inicial.png "3. Plan del Proyecto")



## 1. Importar las librerÃ­as

Las siguientes librerÃ­as son las que se utilizan normalmente en el manejo, anÃ¡lisis y visualizaciÃ³n de datos.  

```python
# Parte 1
# ManipulaciÃ³n de datos con DataFrames.
import pandas as pd

# Operaciones numÃ©ricas y manejo de arrays.
import numpy as np

# CreaciÃ³n de grÃ¡ficos bÃ¡sicos (lÃ­neas, barras, histogramas, etc.).
import matplotlib.pyplot as plt

# VisualizaciÃ³n estadÃ­stica avanzada (mapas de calor, distribuciones).
import seaborn as sns




# Modelado y algoritmos de aprendizaje automÃ¡tico.
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Modelos avanzados de boosting.
import xgboost as xgb
import lightgbm as lgb

# DetecciÃ³n y visualizaciÃ³n de datos nulos.
import missingno as msno

# GrÃ¡ficos interactivos para dashboards.
import plotly.express as px
import plotly.graph_objects as go

# LibrerÃ­as adicionales para entorno Jupyter y manejo interactivo.
from IPython.display import display, HTML
```

**DescripciÃ³n breve de librerÃ­as utilizadas:**
- **pandas**: lectura, limpieza y manipulaciÃ³n de datos tabulares.  
- **numpy**: operaciones matemÃ¡ticas y manejo de vectores o matrices.  
- **matplotlib**: grÃ¡ficos de lÃ­neas, barras, histogramas, etc.  
- **seaborn**: visualizaciones estadÃ­sticas (mapas de calor, distribuciones).  
- **scikit-learn**: modelado y algoritmos de aprendizaje automÃ¡tico.  
- **missingno**: detecciÃ³n y visualizaciÃ³n de datos nulos.  
- **plotly**: grÃ¡ficos interactivos para dashboards.  
- **jupyter**: entorno interactivo para desarrollo y anÃ¡lisis. 
- **xgboost**:	ImplementaciÃ³n optimizada del algoritmo de Extreme Gradient Boosting (XGBoost).
- **lightgbm**:	Algoritmo de Gradient Boosting rÃ¡pido y eficiente desarrollado por Microsoft. 

---

## 2. ConfiguraciÃ³n del Entorno Virtual

Para aislar las dependencias del proyecto y mantener versiones estables.

```bash
# Paso 1: Crear entorno virtual, v3.13 es la maxima compatible con streamlit
py -3.13 -m venv .venv 

# Paso 2: Activar entorno virtual
.venv\Scripts\activate

#Paso 2a seleccionar interprete de python para el entorno virtual
a) Presionar Ctrl + shift + P
b) Click en Pyhton: Select Interpreter
c) Seleccionar el que tenga el entorno virtual, ej.  Pyhton 3.13.19(.venv) .\.venv\Scripts\python.exe

# Instalar Jupyter  para visualizar resultado de los archivos de jupyter
pip install jupyter ipykernel

# Paso 3: Instalar librerÃ­as necesarias y actualizar pip a su nueva version
pip install pandas numpy matplotlib seaborn tabulate

python.exe -m pip install --upgrade pip

pip install scikit-learn missingno plotly streamlit lightgbm xgboost


# Paso 4: Exportar dependencias instaladas, despues se puede usar el comando pip install -r requirements.txt

pip freeze > requirements.txt

# Paso 5: Clonar el repositorio del proyecto
# (Repositorio documentado en 'Github_notes.md')

# Paso 6: Realizar las actividades asignadas

#pip install fastapi "uvicorn[standard]" pydantic
#API
pip install fastapi "uvicorn[standard]" 

#Dashboard
pip install streamlit plotly




#http://127.0.0.1:8000/docs
```

Comentarios:
- `.venv` crea un entorno virtual local.  
- `pip freeze` genera un archivo con versiones exactas de librerÃ­as.  
- `requirements.txt` permite replicar el entorno en otro equipo fÃ¡cilmente.  

---

## 3. Flujo del Proyecto (Flow Project)

Este flujo organiza las etapas principales del anÃ¡lisis y modelado.

1. Carga de los datos (dataset).  
2. AnÃ¡lisis Exploratorio de los Datos (EDA).  
3. PreparaciÃ³n y tratamiento previo de los datos.  
4. VisualizaciÃ³n grÃ¡fica de los datos.  
5. GeneraciÃ³n del modelo de aprendizaje automÃ¡tico.  
6. Entrenamiento del modelo de aprendizaje automÃ¡tico.  
7. DefiniciÃ³n del modelo predictivo.  
8. EvaluaciÃ³n del modelo entrenado con datos reservados.  

### Ejemplos de comandos en EDA

```python
# Vista inicial del dataset
data.head()

# Dimensiones del set de datos
print("TamaÃ±o del set de datos:", data.shape)

# InformaciÃ³n general del dataset
data.info()

# Conteo de valores nulos
data.isnull().sum()

# Conteo de registros duplicados
data.duplicated().sum()
```

Comentarios:
- `data.head()` muestra las primeras filas para verificar estructura.  
- `data.shape` indica cuÃ¡ntas filas y columnas contiene.  
- `data.info()` ayuda a detectar tipos de datos y nulos.  
- `isnull()` y `duplicated()` permiten identificar problemas de calidad.  

### Limpieza de Datos (duplicados y nulos)

```python
# Identificar registros duplicados
duplicated_rows = data[data.duplicated()]
print(duplicated_rows)

# Eliminar filas duplicadas
print("TamaÃ±o antes:", data.shape)
data.drop_duplicates(inplace=True)
print("TamaÃ±o despuÃ©s:", data.shape)

# Identificar valores nulos en la columna 'Artist'
null_artists = data[data['Artist'].isnull()]
print("\nÃndices con artistas nulos:")
print(null_artists.index.tolist())

# Eliminar filas con artistas nulos
print("Nulos antes:", data['Artist'].isnull().sum())
data.dropna(subset=['Artist'], inplace=True)
print("Nulos despuÃ©s:", data['Artist'].isnull().sum())
```

Comentarios:
- `data.duplicated()` localiza registros repetidos.  
- `drop_duplicates()` elimina duplicados sin crear una nueva copia.  
- `dropna()` elimina filas con valores faltantes en columnas clave.  

---

## 4. Enfoque del AnÃ¡lisis Exploratorio

Durante el EDA, se analizan principalmente:
- Datos nulos.  
- Registros duplicados.  
- Valores vacÃ­os o inconsistentes.  
- Distribuciones estadÃ­sticas de cada atributo (por ejemplo, energy, danceability, valence).  

Estos pasos aseguran una base de datos limpia antes del modelado.  

---

# Estructura del Proyecto

```
CASE-STUDY-SPOTIFY/
PRE-TRAINING/
â”‚
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml
â”‚
â”œâ”€â”€ .venv/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ SpotifyFeatures.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ spotify_clean_modeling.csv
â”‚   â”‚   â”œâ”€â”€ spotify_clean.csv
â”‚   â”‚   â”œâ”€â”€ X_test.csv
â”‚   â”‚   â”œâ”€â”€ y_test.csv
â”‚   â”‚   â””â”€â”€ y_pred_model_evaluation.csv
â”‚   â”‚
â”‚   â””â”€â”€ processed/extra/ (si deseas mantener otras versiones)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_loader.ipynb
â”‚   â”œâ”€â”€ 02_eda.ipynb
â”‚   â”œâ”€â”€ 03_preprocessing.ipynb
â”‚   â”œâ”€â”€ 04_model_trainingold.ipynb
â”‚   â””â”€â”€ 05_model_evaluation.ipynb
â”‚
â”œâ”€â”€ notes/
â”‚   â”œâ”€â”€ img/
â”‚   â”‚   â””â”€â”€ img-samples-dashboard/
â”‚   â”‚
â”‚   â”œâ”€â”€ Github_notes.md
â”‚   â”œâ”€â”€ Json_API_test.json
â”‚   â”œâ”€â”€ Markdown_info.md
â”‚   â”œâ”€â”€ Project Flow.md
â”‚   â””â”€â”€ Spotify_Dataset_Description.md
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â””â”€â”€ routes.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ model_pipeline.joblib
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ preprocess.py
â”‚   â”‚   â”œâ”€â”€ static/   (si tu API sirviera archivos estÃ¡ticos)
â”‚   â”‚   â””â”€â”€ requirements_api.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”‚   â””â”€â”€ custom.css
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ 1_metrics.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gauge.py
â”‚   â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â”‚
â”‚   â””â”€â”€ __pycache__/   (ignorado en producciÃ³n)
â”‚
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ Dockerfile
â”‚
â”œâ”€â”€ requirements.txt         (para entorno general)
â””â”€â”€ requirementsApp.txt      (para Streamlit)

```

---

## Recomendaciones

- **processed/**: evita modificar los datos originales; guarda aquÃ­ los datasets limpios.  
- **results/**: Ãºtil para almacenar grÃ¡ficas, mÃ©tricas y comparaciones entre modelos.  
- **utils/**: concentra funciones comunes, como carga de datos, limpieza o visualizaciÃ³n.  
- **api/**: te servirÃ¡ cuando implementes el endpoint `/songs/predict_hit`.  
- **tests/**: si piensas escalar el proyecto o evaluarlo acadÃ©micamente, esto muestra buenas prÃ¡cticas.  

---


# Modelos exactos recomendados (clasificaciÃ³n â€œhit / no hitâ€)

| Tipo                    | Modelos                                                               | PropÃ³sito en tu experimento                        |
|--------------------------|-----------------------------------------------------------------------|----------------------------------------------------|
| **Ãrboles y Ensambles** | RandomForestClassifier, GradientBoostingClassifier, XGBoost, LightGBM | Modelos potentes, capturan relaciones no lineales. |
| **Lineal**              | LogisticRegression                                                    | Baseline interpretable.                            |
| **Distancia**           | KNeighborsClassifier                                                  | Comparativo, sensible al escalado.                 |

---

| Modelo                   | LibrerÃ­a              | ComposiciÃ³n           | CuÃ¡ndo usarlo                                      | ConversiÃ³n de `genre` |
|---------------------------|----------------------|-----------------------|----------------------------------------------------|------------------------|
| **RandomForestClassifier**     | `sklearn.ensemble`    | Ensemble (Ã¡rboles)     | Base sÃ³lida, robusto sin escalar.                  | `LabelEncoder` |
| **GradientBoostingClassifier** | `sklearn.ensemble`    | Ensemble (boosting)    | MÃ¡s preciso, controla bien el overfitting.         | `LabelEncoder` |
| **XGBClassifier**              | `xgboost`             | Boosting avanzado      | PrecisiÃ³n alta, rÃ¡pido.                            | `LabelEncoder` |
| **LGBMClassifier**             | `lightgbm`            | Boosting optimizado    | Muy rÃ¡pido en datasets grandes.                    | `LabelEncoder` |
| **LogisticRegression**         | `sklearn.linear_model` | Lineal                 | Buen baseline interpretativo.                      | `OneHotEncoder` |
| **KNeighborsClassifier**       | `sklearn.neighbors`   | Distancia              | Comparativo; sensible al escalado.                 | `OneHotEncoder` |




| Modelo               | Ajuste aplicado              | Efecto                                                  |
| -------------------- | ---------------------------- | ------------------------------------------------------- |
| `RandomForest`       | `class_weight='balanced'`    | Aumenta la importancia de los hits (clase minoritaria). |
| `GradientBoosting`   | sin soporte directo          | Se deja igual, o puedes balancear por resampling.       |
| `XGBoost`            | `scale_pos_weight=ratio`     | Corrige el desbalance en la funciÃ³n de pÃ©rdida.         |
| `LightGBM`           | `class_weight='balanced'`    | Pondera internamente las clases.                        |
| `LogisticRegression` | `class_weight='balanced'`    | Ajusta los pesos durante la optimizaciÃ³n.               |
| `KNeighbors`         | no soporta pesos automÃ¡ticos | Se mantiene igual.                                      |


Tu dataset tiene solo 4.53 % de canciones â€œhitâ€, lo que provoca que los modelos prioricen predecir â€œno-hitâ€ (clase 0).
Con class_weight='balanced' y scale_pos_weight, cada modelo penaliza mÃ¡s los errores en la clase minoritaria, mejorando recall y F1-score.


### Analisis de Resultado

| Modelo                  | Accuracy | F1-Score (Hit) | ROC AUC | Conclusiones                                                                                                                   |
| ----------------------- | -------- | -------------- | ------- | ------------------------------------------------------------------------------------------------------------------------------ |
| **LightGBM**            | 0.8937   | 0.4439         | 0.8785  | Mejor desempeÃ±o general. Mantiene alto poder de discriminaciÃ³n y el F1 mÃ¡s equilibrado. Ideal para continuar el entrenamiento. |
| **XGBoost**             | 0.8856   | 0.4262         | 0.8740  | Muy competitivo, pero ligeramente inferior a LightGBM en Recall y estabilidad.                                                 |
| **Random Forest**       | 0.8576   | 0.2837         | 0.6986  | Consistente pero sesgado hacia la clase No-Hit.                                                                                |
| **Logistic Regression** | 0.7779   | 0.2646         | 0.8122  | Base lineal razonable, pero limitada para capturar relaciones complejas.                                                       |
| **Gradient Boosting**   | 0.9554   | 0.1321         | 0.5356  | Accuracy inflado; pobre desempeÃ±o en detecciÃ³n de Hits.                                                                        |
| **K-Neighbors**         | 0.9520   | 0.0809         | 0.5214  | Alto Accuracy por sesgo hacia No-Hit. Ineficiente para identificar Hits.                                                       |

---

### ðŸ ConclusiÃ³n final

- **LightGBM** â†’ modelo Ã³ptimo para pasar al archivo `04_model_training.ipynb`.  
- **XGBoost** â†’ referencia secundaria para comparar despuÃ©s del ajuste de hiperparÃ¡metros.

---

### ðŸ“Š MÃ©tricas utilizadas

- **accuracy_score** â†’ mide quÃ© proporciÃ³n de predicciones fueron correctas.  
- **f1_score** â†’ mide el equilibrio entre *precisiÃ³n* y *recall* (Ãºtil si las clases estÃ¡n desbalanceadas).  
- **roc_auc_score** â†’ mide la capacidad del modelo para distinguir entre clases (cuanto mÃ¡s cerca de 1, mejor).


1. Logistic Regression

Modelo lineal.
Sirve como baseline. RÃ¡pido, interpretable y muestra quÃ© variables empujan a la probabilidad de ser hit.

2. Random Forest

Ensamble de muchos Ã¡rboles de decisiÃ³n.
Robusto, maneja no-linealidades y detecta interacciones entre features automÃ¡ticamente.

3. Gradient Boosting (GBM clÃ¡sico de sklearn)

Construye Ã¡rboles de manera secuencial, corrigiendo errores del anterior.
Mejor rendimiento que RandomForest pero mÃ¡s lento.

4. XGBoost

ImplementaciÃ³n optimizada y mÃ¡s poderosa de boosting.
Alta precisiÃ³n, muy usado en competencias de Kaggle. Excelente con datasets tabulares.

5. LightGBM

Boosting muy rÃ¡pido desarrollado por Microsoft.
Funciona excelente con grandes volÃºmenes (como tu dataset de 230k filas).
Suele superar a XGBoost en velocidad con rendimiento similar o mejor.

MÃ©tricas que se van a comparar

Debido al dataset desbalanceado (4.6% hits), no sirve usar solo accuracy.
Por eso se evalÃºan 3 mÃ©tricas clave:

1. Accuracy

Porcentaje de predicciones correctas.
No es muy Ãºtil con desbalance (un modelo que prediga â€œtodo es no-hitâ€ ya logra 95%).

2. F1-score

Promedio entre precision y recall para la clase positiva (hit).
Es la mÃ©trica crÃ­tica cuando la clase â€œhitâ€ es muy minoritaria.
EvalÃºa quÃ© tan bien detecta hits sin generar demasiados falsos positivos.

3. ROC-AUC

Mide la capacidad del modelo de separar ambas clases.
No depende del umbral 0.5.
Valores:

0.5 = aleatorio

1.0 = perfecto
Un buen modelo suele estar > 0.80

En una frase:

Entrenaremos 5 algoritmos (lineales, Ã¡rboles y boostings) y los compararemos usando mÃ©tricas robustas frente al desbalance (F1 y AUC) para seleccionar el mejor modelo que predice si una canciÃ³n puede ser un hit.

Estructura Final SRC
API FastAPI â†’ carpeta src/api/

Modelo entrenado â†’ carpeta src/api/models

Dashboard Streamlit â†’ carpeta src/dashboard/


Publicacion 
                 +------------------------+
                 |   Streamlit Cloud      |
                 |   (Dashboard UI)       |
                 |   https://...app       |
                 +-----------+------------+
                             |
                             |  HTTPS (POST/JSON)
                             v
         +---------------------------------------------+
         |  Railway.app (API FastAPI + Modelo ML)      |
         |  https://<project>.railway.app/predict_hit   |
         +---------------------------------------------+
Dashboard â†’ Streamlit Cloud (sin Docker)
API FastAPI â†’ Railway (con Docker obligatorio)