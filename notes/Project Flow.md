# ğŸ“˜GuÃ­a de ConfiguraciÃ³n y Flujo de Trabajo â€“ AnÃ¡lisis Musical con Python
**Proyecto:** AnÃ¡lisis de Atributos Musicales y PredicciÃ³n de Popularidad de Canciones  

![Arquitectura](img/arquitectura.png "1. Arquitectura")

![Entregable](img/entregable-final.png "2. Entregable final")

![Plan](img/plan-proyecto-inicial.png "3. Plan del Proyecto")



## 1. Importar las librerÃ­as

Las siguientes librerÃ­as son las que se utilizan normalmente en el manejo, anÃ¡lisis y visualizaciÃ³n de datos.  

```python
# ManipulaciÃ³n de datos con DataFrames.
import pandas as pd

# Operaciones numÃ©ricas y manejo de arrays.
import numpy as np

# CreaciÃ³n de grÃ¡ficos bÃ¡sicos (lÃ­neas, barras, histogramas, etc.).
import matplotlib.pyplot as plt

# VisualizaciÃ³n estadÃ­stica avanzada (mapas de calor, distribuciones).
import seaborn as sns

# Mostrar grÃ¡ficos directamente en el entorno de Jupyter.
%matplotlib inline

# Modelado y algoritmos de aprendizaje automÃ¡tico.
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Modelos avanzados de boosting.
import xgboost as xgb
import lightgbm as lgb

# DetecciÃ³n y visualizaciÃ³n de datos nulos.
import missingno as msno

# GrÃ¡ficos interactivos para dashboards.
import plotly.express as px
import plotly.graph_objects as go

# LibrerÃ­as adicionales para entorno Jupyter y manejo interactivo.
from IPython.display import display, HTML
```

**DescripciÃ³n breve de librerÃ­as utilizadas:**
- **pandas**: lectura, limpieza y manipulaciÃ³n de datos tabulares.  
- **numpy**: operaciones matemÃ¡ticas y manejo de vectores o matrices.  
- **matplotlib**: grÃ¡ficos de lÃ­neas, barras, histogramas, etc.  
- **seaborn**: visualizaciones estadÃ­sticas (mapas de calor, distribuciones).  
- **scikit-learn**: modelado y algoritmos de aprendizaje automÃ¡tico.  
- **missingno**: detecciÃ³n y visualizaciÃ³n de datos nulos.  
- **plotly**: grÃ¡ficos interactivos para dashboards.  
- **jupyter**: entorno interactivo para desarrollo y anÃ¡lisis. 
- **xgboost**:	ImplementaciÃ³n optimizada del algoritmo de Extreme Gradient Boosting (XGBoost).
- **lightgbm**:	Algoritmo de Gradient Boosting rÃ¡pido y eficiente desarrollado por Microsoft. 

---

## 2. ConfiguraciÃ³n del Entorno Virtual

Para aislar las dependencias del proyecto y mantener versiones estables.

```bash
# Paso 1: Crear entorno virtual, v3.13 es la maxima compatible con streamlit
py -3.13 -m venv .venv 

# Paso 2: Activar entorno virtual
.venv\Scripts\activate

#Paso 2a seleccionar interprete de python para el entorno virtual
a) Presionar Ctrl + shift + P
b) Click en Pyhton: Select Interpreter
c) Seleccionar el que tenga el entorno virtual, ej.  Pyhton 3.13.19(.venv) .\.venv\Scripts\python.exe


# Paso 3: Instalar librerÃ­as necesarias
pip install pandas numpy matplotlib seaborn scikit-learn jupyter missingno plotly streamlit lightgbm xgboost


# Paso 4: Exportar dependencias instaladas
pip freeze > requirements.txt

# Paso 5: Clonar el repositorio del proyecto
# (Repositorio documentado en 'Github_notes.md')

# Paso 6: Realizar las actividades asignadas
```

Comentarios:
- `.venv` crea un entorno virtual local.  
- `pip freeze` genera un archivo con versiones exactas de librerÃ­as.  
- `requirements.txt` permite replicar el entorno en otro equipo fÃ¡cilmente.  

---

## 3. Flujo del Proyecto (Flow Project)

Este flujo organiza las etapas principales del anÃ¡lisis y modelado.

1. Carga de los datos (dataset).  
2. AnÃ¡lisis Exploratorio de los Datos (EDA).  
3. PreparaciÃ³n y tratamiento previo de los datos.  
4. VisualizaciÃ³n grÃ¡fica de los datos.  
5. GeneraciÃ³n del modelo de aprendizaje automÃ¡tico.  
6. Entrenamiento del modelo de aprendizaje automÃ¡tico.  
7. DefiniciÃ³n del modelo predictivo.  
8. EvaluaciÃ³n del modelo entrenado con datos reservados.  

### Ejemplos de comandos en EDA

```python
# Vista inicial del dataset
data.head()

# Dimensiones del set de datos
print("TamaÃ±o del set de datos:", data.shape)

# InformaciÃ³n general del dataset
data.info()

# Conteo de valores nulos
data.isnull().sum()

# Conteo de registros duplicados
data.duplicated().sum()
```

Comentarios:
- `data.head()` muestra las primeras filas para verificar estructura.  
- `data.shape` indica cuÃ¡ntas filas y columnas contiene.  
- `data.info()` ayuda a detectar tipos de datos y nulos.  
- `isnull()` y `duplicated()` permiten identificar problemas de calidad.  

### Limpieza de Datos (duplicados y nulos)

```python
# Identificar registros duplicados
duplicated_rows = data[data.duplicated()]
print(duplicated_rows)

# Eliminar filas duplicadas
print("TamaÃ±o antes:", data.shape)
data.drop_duplicates(inplace=True)
print("TamaÃ±o despuÃ©s:", data.shape)

# Identificar valores nulos en la columna 'Artist'
null_artists = data[data['Artist'].isnull()]
print("\nÃndices con artistas nulos:")
print(null_artists.index.tolist())

# Eliminar filas con artistas nulos
print("Nulos antes:", data['Artist'].isnull().sum())
data.dropna(subset=['Artist'], inplace=True)
print("Nulos despuÃ©s:", data['Artist'].isnull().sum())
```

Comentarios:
- `data.duplicated()` localiza registros repetidos.  
- `drop_duplicates()` elimina duplicados sin crear una nueva copia.  
- `dropna()` elimina filas con valores faltantes en columnas clave.  

---

## 4. Enfoque del AnÃ¡lisis Exploratorio

Durante el EDA, se analizan principalmente:
- Datos nulos.  
- Registros duplicados.  
- Valores vacÃ­os o inconsistentes.  
- Distribuciones estadÃ­sticas de cada atributo (por ejemplo, energy, danceability, valence).  

Estos pasos aseguran una base de datos limpia antes del modelado.  

---

# Estructura Sugerida Proyecto

```
CASE-STUDY-SPOTIFY/
â”‚
â”œâ”€â”€ data/                     # Datos originales y procesados
â”‚   â”œâ”€â”€ SpotifyFeatures.csv
â”‚   â”œâ”€â”€ processed/            # Datasets limpios o con feature engineering
â”‚   â”‚   â””â”€â”€ spotify_clean.csv
â”‚
â”œâ”€â”€ models/                   # Modelos entrenados y scripts de entrenamiento
â”‚   â”œâ”€â”€ random_forest.pkl
â”‚   â”œâ”€â”€ xgboost_model.json
â”‚   â””â”€â”€ lightgbm_model.txt
â”‚
â”œâ”€â”€ notebooks/                # Jupyter Notebooks de anÃ¡lisis
â”‚   â”œâ”€â”€ 01_loader.ipynb
â”‚   â”œâ”€â”€ 02_eda.ipynb
â”‚   â”œâ”€â”€ 03_preprocessing.ipynb
â”‚   â”œâ”€â”€ 04_model_training.ipynb
â”‚   â””â”€â”€ 05_evaluation.ipynb
â”‚
â”œâ”€â”€ notes/                    # DocumentaciÃ³n y apuntes
â”‚   â”œâ”€â”€ img/
â”‚   â”œâ”€â”€ Github_notes.md
â”‚   â”œâ”€â”€ Markdown_info.md
â”‚   â””â”€â”€ Project Flow.md
â”‚
â”œâ”€â”€ src/                      # CÃ³digo fuente del proyecto
â”‚   â”œâ”€â”€ utils/                # Funciones auxiliares reutilizables
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â”œâ”€â”€ visualizations.py
â”‚   â”‚   â””â”€â”€ model_utils.py
â”‚   â””â”€â”€ api/                  # API predictiva (Flask o FastAPI)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ routes.py
â”‚
â”œâ”€â”€ results/                  # Resultados del modelo y grÃ¡ficos
â”‚   â”œâ”€â”€ figures/              # GrÃ¡ficos de anÃ¡lisis
â”‚   â””â”€â”€ metrics/              # Reportes y tablas de evaluaciÃ³n
â”‚
â”œâ”€â”€ tests/                    # Pruebas unitarias del cÃ³digo
â”‚   â”œâ”€â”€ test_data_loader.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ main.py                   # Punto inicial del proyecto
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ setup.md                  # GuÃ­a de instalaciÃ³n y entorno
```

---

## Recomendaciones

- **processed/**: evita modificar los datos originales; guarda aquÃ­ los datasets limpios.  
- **results/**: Ãºtil para almacenar grÃ¡ficas, mÃ©tricas y comparaciones entre modelos.  
- **utils/**: concentra funciones comunes, como carga de datos, limpieza o visualizaciÃ³n.  
- **api/**: te servirÃ¡ cuando implementes el endpoint `/songs/predict_hit`.  
- **tests/**: si piensas escalar el proyecto o evaluarlo acadÃ©micamente, esto muestra buenas prÃ¡cticas.  

---