# ğŸ“˜GuÃ­a de ConfiguraciÃ³n y Flujo de Trabajo â€“ AnÃ¡lisis Musical con Python
**Proyecto:** AnÃ¡lisis de Atributos Musicales y PredicciÃ³n de Popularidad de Canciones  

![Arquitectura](img/arquitectura.png "1. Arquitectura")

![Entregable](img/entregable-final.png "2. Entregable final")

![Plan](img/plan-proyecto-inicial.png "3. Plan del Proyecto")



## 1. Importar las librerÃ­as

Las siguientes librerÃ­as son las que se utilizan normalmente en el manejo, anÃ¡lisis y visualizaciÃ³n de datos.  

```python
# Parte 1
# ManipulaciÃ³n de datos con DataFrames.
import pandas as pd

# Operaciones numÃ©ricas y manejo de arrays.
import numpy as np

# CreaciÃ³n de grÃ¡ficos bÃ¡sicos (lÃ­neas, barras, histogramas, etc.).
import matplotlib.pyplot as plt

# VisualizaciÃ³n estadÃ­stica avanzada (mapas de calor, distribuciones).
import seaborn as sns




# Modelado y algoritmos de aprendizaje automÃ¡tico.
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Modelos avanzados de boosting.
import xgboost as xgb
import lightgbm as lgb

# DetecciÃ³n y visualizaciÃ³n de datos nulos.
import missingno as msno

# GrÃ¡ficos interactivos para dashboards.
import plotly.express as px
import plotly.graph_objects as go

# LibrerÃ­as adicionales para entorno Jupyter y manejo interactivo.
from IPython.display import display, HTML
```

**DescripciÃ³n breve de librerÃ­as utilizadas:**
- **pandas**: lectura, limpieza y manipulaciÃ³n de datos tabulares.  
- **numpy**: operaciones matemÃ¡ticas y manejo de vectores o matrices.  
- **matplotlib**: grÃ¡ficos de lÃ­neas, barras, histogramas, etc.  
- **seaborn**: visualizaciones estadÃ­sticas (mapas de calor, distribuciones).  
- **scikit-learn**: modelado y algoritmos de aprendizaje automÃ¡tico.  
- **missingno**: detecciÃ³n y visualizaciÃ³n de datos nulos.  
- **plotly**: grÃ¡ficos interactivos para dashboards.  
- **jupyter**: entorno interactivo para desarrollo y anÃ¡lisis. 
- **xgboost**:	ImplementaciÃ³n optimizada del algoritmo de Extreme Gradient Boosting (XGBoost).
- **lightgbm**:	Algoritmo de Gradient Boosting rÃ¡pido y eficiente desarrollado por Microsoft. 

---

## 2. ConfiguraciÃ³n del Entorno Virtual

Para aislar las dependencias del proyecto y mantener versiones estables.

```bash
# Paso 1: Crear entorno virtual, v3.13 es la maxima compatible con streamlit
py -3.13 -m venv .venv 

# Paso 2: Activar entorno virtual
.venv\Scripts\activate

#Paso 2a seleccionar interprete de python para el entorno virtual
a) Presionar Ctrl + shift + P
b) Click en Pyhton: Select Interpreter
c) Seleccionar el que tenga el entorno virtual, ej.  Pyhton 3.13.19(.venv) .\.venv\Scripts\python.exe

# Instalar Jupyter  para visualizar resultado de los archivos de jupyter
pip install jupyter ipykernel

# Paso 3: Instalar librerÃ­as necesarias y actualizar pip a su nueva version
pip install pandas numpy matplotlib seaborn tabulate

python.exe -m pip install --upgrade pip

pip install scikit-learn missingno plotly streamlit lightgbm xgboost


# Paso 4: Exportar dependencias instaladas, despues se puede usar el comando pip install -r requirements.txt

pip freeze > requirements.txt

# Paso 5: Clonar el repositorio del proyecto
# (Repositorio documentado en 'Github_notes.md')

# Paso 6: Realizar las actividades asignadas

pip install fastapi "uvicorsn[standard]" pydantic

#http://127.0.0.1:8000/docs
```

Comentarios:
- `.venv` crea un entorno virtual local.  
- `pip freeze` genera un archivo con versiones exactas de librerÃ­as.  
- `requirements.txt` permite replicar el entorno en otro equipo fÃ¡cilmente.  

---

## 3. Flujo del Proyecto (Flow Project)

Este flujo organiza las etapas principales del anÃ¡lisis y modelado.

1. Carga de los datos (dataset).  
2. AnÃ¡lisis Exploratorio de los Datos (EDA).  
3. PreparaciÃ³n y tratamiento previo de los datos.  
4. VisualizaciÃ³n grÃ¡fica de los datos.  
5. GeneraciÃ³n del modelo de aprendizaje automÃ¡tico.  
6. Entrenamiento del modelo de aprendizaje automÃ¡tico.  
7. DefiniciÃ³n del modelo predictivo.  
8. EvaluaciÃ³n del modelo entrenado con datos reservados.  

### Ejemplos de comandos en EDA

```python
# Vista inicial del dataset
data.head()

# Dimensiones del set de datos
print("TamaÃ±o del set de datos:", data.shape)

# InformaciÃ³n general del dataset
data.info()

# Conteo de valores nulos
data.isnull().sum()

# Conteo de registros duplicados
data.duplicated().sum()
```

Comentarios:
- `data.head()` muestra las primeras filas para verificar estructura.  
- `data.shape` indica cuÃ¡ntas filas y columnas contiene.  
- `data.info()` ayuda a detectar tipos de datos y nulos.  
- `isnull()` y `duplicated()` permiten identificar problemas de calidad.  

### Limpieza de Datos (duplicados y nulos)

```python
# Identificar registros duplicados
duplicated_rows = data[data.duplicated()]
print(duplicated_rows)

# Eliminar filas duplicadas
print("TamaÃ±o antes:", data.shape)
data.drop_duplicates(inplace=True)
print("TamaÃ±o despuÃ©s:", data.shape)

# Identificar valores nulos en la columna 'Artist'
null_artists = data[data['Artist'].isnull()]
print("\nÃndices con artistas nulos:")
print(null_artists.index.tolist())

# Eliminar filas con artistas nulos
print("Nulos antes:", data['Artist'].isnull().sum())
data.dropna(subset=['Artist'], inplace=True)
print("Nulos despuÃ©s:", data['Artist'].isnull().sum())
```

Comentarios:
- `data.duplicated()` localiza registros repetidos.  
- `drop_duplicates()` elimina duplicados sin crear una nueva copia.  
- `dropna()` elimina filas con valores faltantes en columnas clave.  

---

## 4. Enfoque del AnÃ¡lisis Exploratorio

Durante el EDA, se analizan principalmente:
- Datos nulos.  
- Registros duplicados.  
- Valores vacÃ­os o inconsistentes.  
- Distribuciones estadÃ­sticas de cada atributo (por ejemplo, energy, danceability, valence).  

Estos pasos aseguran una base de datos limpia antes del modelado.  

---

# Estructura del Proyecto

```
CASE-STUDY-SPOTIFY/
â”‚
â”œâ”€â”€ data/                     
â”‚   â”œâ”€â”€ raw/                  # Datos originales intactos y limpios
â”‚   â”‚   â””â”€â”€ SpotifyFeatures.csv
â”‚   â”œâ”€â”€ processed/            
â”‚   â”‚   â””â”€â”€ spotify_clean.csv
â”‚
â”œâ”€â”€ models/                   
â”‚   â”œâ”€â”€ random_forest.pkl
â”‚   â”œâ”€â”€ xgboost_model.json
â”‚   â”œâ”€â”€ lightgbm_model.txt
â”‚   â””â”€â”€ scaler.pkl            # Escalador o encoder
â”‚
â”œâ”€â”€ notebooks/                
â”‚   â”œâ”€â”€ 01_loader.ipynb
â”‚   â”œâ”€â”€ 02_eda.ipynb
â”‚   â”œâ”€â”€ 03_preprocessing.ipynb
â”‚   â”œâ”€â”€ 04_model_training.ipynb
â”‚   â””â”€â”€ 05_evaluation.ipynb
â”‚
â”œâ”€â”€ notes/                    
â”‚   â”œâ”€â”€ img/
â”‚   â”œâ”€â”€ Github_notes.md
â”‚   â”œâ”€â”€ Markdown_info.md
â”‚   â”œâ”€â”€ Project Flow.md
â”‚   â””â”€â”€ References.md         # BibliografÃ­a y links Ãºtiles
â”‚
â”œâ”€â”€ src/                      
â”‚   â”œâ”€â”€ utils/                
â”‚   â”‚   â”œâ”€â”€ __init__.py       # Importaciones como mÃ³dulo Python
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â”œâ”€â”€ visualizations.py
â”‚   â”‚   â””â”€â”€ model_utils.py
â”‚   â”œâ”€â”€ api/                  
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â””â”€â”€ model_service.py  # FunciÃ³n predictiva central (load_model + predict)
â”‚   â””â”€â”€ dashboard/            # Streamlit app
â”‚       â””â”€â”€ buscador_de_hits.py
â”‚
â”œâ”€â”€ results/                  
â”‚   â”œâ”€â”€ figures/              
â”‚   â”œâ”€â”€ metrics/              
â”‚   â””â”€â”€ reports/              # PDF o notebooks convertidos a HTML/PDF
â”‚
â”œâ”€â”€ tests/                    
â”‚   â”œâ”€â”€ test_data_loader.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ main.py                   
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.md                  
â””â”€â”€ environment.yml            # entorno reproducible (conda o venv) Docker

```

---

## Recomendaciones

- **processed/**: evita modificar los datos originales; guarda aquÃ­ los datasets limpios.  
- **results/**: Ãºtil para almacenar grÃ¡ficas, mÃ©tricas y comparaciones entre modelos.  
- **utils/**: concentra funciones comunes, como carga de datos, limpieza o visualizaciÃ³n.  
- **api/**: te servirÃ¡ cuando implementes el endpoint `/songs/predict_hit`.  
- **tests/**: si piensas escalar el proyecto o evaluarlo acadÃ©micamente, esto muestra buenas prÃ¡cticas.  

---


# Modelos exactos recomendados (clasificaciÃ³n â€œhit / no hitâ€)

| Tipo                    | Modelos                                                               | PropÃ³sito en tu experimento                        |
|--------------------------|-----------------------------------------------------------------------|----------------------------------------------------|
| **Ãrboles y Ensambles** | RandomForestClassifier, GradientBoostingClassifier, XGBoost, LightGBM | Modelos potentes, capturan relaciones no lineales. |
| **Lineal**              | LogisticRegression                                                    | Baseline interpretable.                            |
| **Distancia**           | KNeighborsClassifier                                                  | Comparativo, sensible al escalado.                 |

---

| Modelo                   | LibrerÃ­a              | ComposiciÃ³n           | CuÃ¡ndo usarlo                                      | ConversiÃ³n de `genre` |
|---------------------------|----------------------|-----------------------|----------------------------------------------------|------------------------|
| **RandomForestClassifier**     | `sklearn.ensemble`    | Ensemble (Ã¡rboles)     | Base sÃ³lida, robusto sin escalar.                  | `LabelEncoder` |
| **GradientBoostingClassifier** | `sklearn.ensemble`    | Ensemble (boosting)    | MÃ¡s preciso, controla bien el overfitting.         | `LabelEncoder` |
| **XGBClassifier**              | `xgboost`             | Boosting avanzado      | PrecisiÃ³n alta, rÃ¡pido.                            | `LabelEncoder` |
| **LGBMClassifier**             | `lightgbm`            | Boosting optimizado    | Muy rÃ¡pido en datasets grandes.                    | `LabelEncoder` |
| **LogisticRegression**         | `sklearn.linear_model` | Lineal                 | Buen baseline interpretativo.                      | `OneHotEncoder` |
| **KNeighborsClassifier**       | `sklearn.neighbors`   | Distancia              | Comparativo; sensible al escalado.                 | `OneHotEncoder` |




| Modelo               | Ajuste aplicado              | Efecto                                                  |
| -------------------- | ---------------------------- | ------------------------------------------------------- |
| `RandomForest`       | `class_weight='balanced'`    | Aumenta la importancia de los hits (clase minoritaria). |
| `GradientBoosting`   | sin soporte directo          | Se deja igual, o puedes balancear por resampling.       |
| `XGBoost`            | `scale_pos_weight=ratio`     | Corrige el desbalance en la funciÃ³n de pÃ©rdida.         |
| `LightGBM`           | `class_weight='balanced'`    | Pondera internamente las clases.                        |
| `LogisticRegression` | `class_weight='balanced'`    | Ajusta los pesos durante la optimizaciÃ³n.               |
| `KNeighbors`         | no soporta pesos automÃ¡ticos | Se mantiene igual.                                      |


Tu dataset tiene solo 4.53 % de canciones â€œhitâ€, lo que provoca que los modelos prioricen predecir â€œno-hitâ€ (clase 0).
Con class_weight='balanced' y scale_pos_weight, cada modelo penaliza mÃ¡s los errores en la clase minoritaria, mejorando recall y F1-score.


### Analisis de Resultado

| Modelo                  | Accuracy | F1-Score (Hit) | ROC AUC | Conclusiones                                                                                                                   |
| ----------------------- | -------- | -------------- | ------- | ------------------------------------------------------------------------------------------------------------------------------ |
| **LightGBM**            | 0.8937   | 0.4439         | 0.8785  | Mejor desempeÃ±o general. Mantiene alto poder de discriminaciÃ³n y el F1 mÃ¡s equilibrado. Ideal para continuar el entrenamiento. |
| **XGBoost**             | 0.8856   | 0.4262         | 0.8740  | Muy competitivo, pero ligeramente inferior a LightGBM en Recall y estabilidad.                                                 |
| **Random Forest**       | 0.8576   | 0.2837         | 0.6986  | Consistente pero sesgado hacia la clase No-Hit.                                                                                |
| **Logistic Regression** | 0.7779   | 0.2646         | 0.8122  | Base lineal razonable, pero limitada para capturar relaciones complejas.                                                       |
| **Gradient Boosting**   | 0.9554   | 0.1321         | 0.5356  | Accuracy inflado; pobre desempeÃ±o en detecciÃ³n de Hits.                                                                        |
| **K-Neighbors**         | 0.9520   | 0.0809         | 0.5214  | Alto Accuracy por sesgo hacia No-Hit. Ineficiente para identificar Hits.                                                       |

---

### ğŸ ConclusiÃ³n final

- **LightGBM** â†’ modelo Ã³ptimo para pasar al archivo `04_model_training.ipynb`.  
- **XGBoost** â†’ referencia secundaria para comparar despuÃ©s del ajuste de hiperparÃ¡metros.

---

### ğŸ“Š MÃ©tricas utilizadas

- **accuracy_score** â†’ mide quÃ© proporciÃ³n de predicciones fueron correctas.  
- **f1_score** â†’ mide el equilibrio entre *precisiÃ³n* y *recall* (Ãºtil si las clases estÃ¡n desbalanceadas).  
- **roc_auc_score** â†’ mide la capacidad del modelo para distinguir entre clases (cuanto mÃ¡s cerca de 1, mejor).
