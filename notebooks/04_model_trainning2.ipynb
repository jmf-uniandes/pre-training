{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49cb6ef7",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24617d77",
   "metadata": {},
   "source": [
    "### **1. Carga del dataset procesado**\n",
    "Se utiliza el archivo limpio **`spotify_clean_modeling.csv`**, previamente generado en la etapa de preprocesamiento.\n",
    "\n",
    "### **2. Separación de variables predictoras (X) y objetivo (y)**\n",
    "- **X:** atributos musicales numéricos y categóricos.  \n",
    "- **y:** variable binaria **`is_hit`**, que indica si una canción es considerada un “hit”.\n",
    "\n",
    "### **3. Preparación del preprocesamiento**\n",
    "- Identificación de columnas numéricas y categóricas.\n",
    "- Aplicación de **OneHotEncoder** a las variables categóricas.\n",
    "- Construcción de un **ColumnTransformer** para combinar:\n",
    "  - Codificación One-Hot  \n",
    "  - Paso directo de variables numéricas\n",
    "\n",
    "### **4. Construcción del pipeline del modelo**\n",
    "Se integra el preprocesador y el algoritmo dentro de un único **Pipeline**, garantizando un flujo reproducible y listo para producción.\n",
    "\n",
    "### **5. División del conjunto de datos**\n",
    "- Separación en entrenamiento y prueba mediante `train_test_split`.  \n",
    "- Uso de `stratify=y` para mantener la proporción de clases.\n",
    "\n",
    "### **6. Entrenamiento del modelo LightGBM**\n",
    "- Ajuste del modelo utilizando `class_weight=\"balanced\"` para corregir el fuerte desbalance de clases.  \n",
    "- Entrenamiento del pipeline completo sobre el conjunto de entrenamiento.\n",
    "\n",
    "### **7. Evaluación inicial del modelo**\n",
    "Métricas calculadas sobre el conjunto de prueba:\n",
    "- **Accuracy**  \n",
    "- **F1-score** (clave por el desbalance)  \n",
    "- **ROC-AUC**\n",
    "\n",
    "### **8. Optimización del umbral de decisión (threshold tuning)**\n",
    "- Evaluación del **F1-score** para múltiples umbrales.  \n",
    "- Selección del threshold que maximiza la detección correcta de canciones exitosas.\n",
    "\n",
    "### **9. Evaluación final con threshold optimizado**\n",
    "- Comparación de métricas con el nuevo umbral seleccionado.  \n",
    "- Confirmación de mejoras en la detección de la clase positiva (**hits**).\n",
    "\n",
    "### **10. Guardado del modelo entrenado**\n",
    "- Serialización del pipeline completo mediante **`joblib`**.  \n",
    "- Generación del archivo **`lightgbm_hit_classifier.joblib`** para su uso futuro en:\n",
    "  - Módulo de inferencia  \n",
    "  - API `/songs/predict_hit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "953af501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from lightgbm import LGBMClassifier\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from sklearn import set_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0fec0047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset se ha cargado correctamente en un arreglo: (232724, 15)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ruta al archivo fuente inicial \n",
    "DATA_PATH = \"../data/processed/spotify_clean_modeling.csv\"\n",
    "\n",
    "# Verificar existencia\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"No se encontró el archivo en {DATA_PATH}\")\n",
    "\n",
    "# Carga el archivo CSV\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Dataset se ha cargado correctamente en un arreglo: {df.shape}\")\n",
    "#display(df.columns.T)\n",
    "#display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7457e10",
   "metadata": {},
   "source": [
    "### 2. Separación de variables predictoras (X) y objetivo (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7c0e7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X shape:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(232724, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'X columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['genre', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
       "       'instrumentalness', 'liveness', 'loudness', 'mode', 'speechiness',\n",
       "       'tempo', 'time_signature', 'valence'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de y:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "is_hit\n",
       "0    0.954693\n",
       "1    0.045307\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separación de variables predictoras (X) y objetivo (y)\n",
    "X = df.drop(columns=[\"is_hit\",\"popularity\"])\n",
    "y = df[\"is_hit\"]\n",
    "\n",
    "display(\"X shape:\", X.shape)\n",
    "display(\"X columns:\", X.columns.T)\n",
    "print(\"Distribución de y:\")\n",
    "display(y.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a6b810",
   "metadata": {},
   "source": [
    "### 3. Código: preprocesamiento (OneHot + ColumnTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a0936c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas numéricas: ['acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence']\n",
      "Columnas categóricas: ['genre']\n"
     ]
    }
   ],
   "source": [
    "# Preservacion de DataFrames\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Identificación de columnas numéricas y categóricas\n",
    "numeric_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(\"Columnas numéricas:\", numeric_cols)\n",
    "print(\"Columnas categóricas:\", categorical_cols)\n",
    "\n",
    "# Definición del preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numeric_cols),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb158c",
   "metadata": {},
   "source": [
    "### 4. Código: modelo LightGBM + Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c198400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo LightGBM\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=1200,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=128,\n",
    "    max_depth=-1,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Construcción del pipeline completo\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", model),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa3747",
   "metadata": {},
   "source": [
    "### 5. Código: train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c24cef9",
   "metadata": {},
   "source": [
    "70% → train (para entrenar modelos)\n",
    "\n",
    "10% → validation (para buscar el mejor threshold)\n",
    "\n",
    "20% → test (solo para evaluar al final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "315e77f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162906, 13) → train (70%)\n",
      "(23273, 13) → validation (10%)\n",
      "(46545, 13) → test (20%)\n"
     ]
    }
   ],
   "source": [
    "# 1. Split train/test (80 / 20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 2. Split interno train/val (70 / 10)\n",
    "X_trainModel, X_val, y_trainModel, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.125,        # 0.125 de 80% = 10%\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(X_trainModel.shape, \"→ train (70%)\")\n",
    "print(X_val.shape,        \"→ validation (10%)\")\n",
    "print(X_test.shape,       \"→ test (20%)\")\n",
    "\n",
    "# 3. Restaurar nombres de columnas \n",
    "X_trainModel = pd.DataFrame(X_trainModel, columns=X.columns)\n",
    "X_val        = pd.DataFrame(X_val,        columns=X.columns)\n",
    "X_test       = pd.DataFrame(X_test,       columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d0946",
   "metadata": {},
   "source": [
    "### 6. Entrenamiento del modelo LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8717c660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento completado.\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "pipeline.fit(X_trainModel, y_trainModel)\n",
    "print(\"Entrenamiento completado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561bf4f2",
   "metadata": {},
   "source": [
    "### 7. Código: evaluación inicial (threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b99cf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.9337\n",
      "F1-score:   0.5313\n",
      "ROC-AUC:    0.9603\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96     44436\n",
      "           1       0.39      0.83      0.53      2109\n",
      "\n",
      "    accuracy                           0.93     46545\n",
      "   macro avg       0.69      0.88      0.75     46545\n",
      "weighted avg       0.96      0.93      0.94     46545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluación inicial (umbral por defecto 0.5)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"Accuracy:   {acc:.4f}\")\n",
    "print(f\"F1-score:   {f1:.4f}\")\n",
    "print(f\"ROC-AUC:    {auc:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7cb4d6",
   "metadata": {},
   "source": [
    "### 8. Optimización del umbral de decisión (threshold tuning - F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed77119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor threshold (val): 0.764\n",
      "Mejor F1-score (val): 0.6807\n"
     ]
    }
   ],
   "source": [
    "# 1. Probabilidades en VALIDATION\n",
    "y_proba_val = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 2. Threshold tuning usando  VALIDATION\n",
    "thresholds = np.linspace(0.05, 0.95, 30)\n",
    "f1_scores = []\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (y_proba_val >= t).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))   \n",
    "\n",
    "best_t = thresholds[np.argmax(f1_scores)]\n",
    "best_f1 = max(f1_scores)\n",
    "\n",
    "print(f\"Mejor threshold (val): {best_t:.3f}\")\n",
    "print(f\"Mejor F1-score (val): {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce673ca",
   "metadata": {},
   "source": [
    "### 9. Evaluación final con threshold optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bb56c0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Métricas con threshold optimizado (TEST) ===\n",
      "Accuracy: 0.9732\n",
      "F1-score:0.6853\n",
      "ROC-AUC: 0.9603\n"
     ]
    }
   ],
   "source": [
    "# 1. Probabilidades en el conjunto de TEST\n",
    "y_proba_test = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 2. Aplicar threshold óptimo encontrado en VALIDATION\n",
    "y_pred_opt = (y_proba_test >= best_t).astype(int)\n",
    "\n",
    "# 3. Calcular métricas sobre TEST\n",
    "acc_opt = accuracy_score(y_test, y_pred_opt)\n",
    "f1_opt  = f1_score(y_test, y_pred_opt)\n",
    "auc_opt = roc_auc_score(y_test, y_proba_test)\n",
    "\n",
    "print(\"=== Métricas con threshold optimizado (TEST) ===\")\n",
    "print(f\"Accuracy: {acc_opt:.4f}\")\n",
    "print(f\"F1-score:{f1_opt:.4f}\")\n",
    "print(f\"ROC-AUC: {auc_opt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28152b03",
   "metadata": {},
   "source": [
    "### 10. Guardado del modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "64426f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: ../models/spotify_lightgbm_hit_classifier.joblib\n"
     ]
    }
   ],
   "source": [
    "# Guardado del modelo entrenado\n",
    "MODEL_PATH = \"../models/spotify_lightgbm_hit_classifier.joblib\"\n",
    "joblib.dump(pipeline, MODEL_PATH)\n",
    "print(f\"Modelo guardado en: {MODEL_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
