{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49cb6ef7",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24617d77",
   "metadata": {},
   "source": [
    "### **1. Carga del dataset procesado**\n",
    "Se utiliza el archivo limpio **`spotify_clean_modeling.csv`**, previamente generado en la etapa de preprocesamiento.\n",
    "\n",
    "### **2. Separación de variables predictoras (X) y objetivo (y)**\n",
    "- **X:** atributos musicales numéricos y categóricos.  \n",
    "- **y:** variable binaria **`is_hit`**, que indica si una canción es considerada un “hit”.\n",
    "\n",
    "### **3. Preparación del preprocesamiento**\n",
    "- Identificación de columnas numéricas y categóricas.\n",
    "- Aplicación de **OneHotEncoder** a las variables categóricas.\n",
    "- Construcción de un **ColumnTransformer** para combinar:\n",
    "  - Codificación One-Hot  \n",
    "  - Paso directo de variables numéricas\n",
    "\n",
    "### **4. Construcción del pipeline del modelo**\n",
    "Se integra el preprocesador y el algoritmo dentro de un único **Pipeline**, garantizando un flujo reproducible y listo para producción.\n",
    "\n",
    "### **5. División del conjunto de datos**\n",
    "- Separación en entrenamiento y prueba mediante `train_test_split`.  \n",
    "- Uso de `stratify=y` para mantener la proporción de clases.\n",
    "\n",
    "### **6. Entrenamiento del modelo LightGBM**\n",
    "- Ajuste del modelo utilizando `class_weight=\"balanced\"` para corregir el fuerte desbalance de clases.  \n",
    "- Entrenamiento del pipeline completo sobre el conjunto de entrenamiento.\n",
    "\n",
    "### **7. Evaluación inicial del modelo**\n",
    "Métricas calculadas sobre el conjunto de prueba:\n",
    "- **Accuracy**  \n",
    "- **F1-score** (clave por el desbalance)  \n",
    "- **ROC-AUC**\n",
    "\n",
    "### **8. Optimización del umbral de decisión (threshold tuning)**\n",
    "- Evaluación del **F1-score** para múltiples umbrales.  \n",
    "- Selección del threshold que maximiza la detección correcta de canciones exitosas.\n",
    "\n",
    "### **9. Evaluación final con threshold optimizado**\n",
    "- Comparación de métricas con el nuevo umbral seleccionado.  \n",
    "- Confirmación de mejoras en la detección de la clase positiva (**hits**).\n",
    "\n",
    "### **10. Guardado del modelo entrenado**\n",
    "- Serialización del pipeline completo mediante **`joblib`**.  \n",
    "- Generación del archivo **`lightgbm_hit_classifier.joblib`** para su uso futuro en:\n",
    "  - Módulo de inferencia  \n",
    "  - API `/songs/predict_hit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953af501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from sklearn import set_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fec0047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset se ha cargado correctamente en un arreglo: (232724, 24)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ruta al archivo fuente inicial \n",
    "DATA_PATH = \"../data/processed/spotify_clean_modeling.csv\"\n",
    "\n",
    "# Verificar existencia\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"No se encontró el archivo en {DATA_PATH}\")\n",
    "\n",
    "# Carga el archivo CSV\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Dataset se ha cargado correctamente en un arreglo: {df.shape}\")\n",
    "#display(df.columns.T)\n",
    "#display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7457e10",
   "metadata": {},
   "source": [
    "### 2. Separación de variables predictoras (X) y objetivo (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c0e7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X shape:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(232724, 22)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'X columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['genre', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
       "       'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo',\n",
       "       'valence', 'beat_density', 'energy_valence', 'dance_energy',\n",
       "       'tempo_norm', 'loudness_norm', 'speech_valence', 'acoustic_energy',\n",
       "       'inst_energy', 'dance_valence', 'duration_min', 'duration_norm'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de y:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "is_hit\n",
       "0    0.903981\n",
       "1    0.096019\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separación de variables predictoras (X) y objetivo (y)\n",
    "X = df.drop(columns=[\"is_hit\",\"popularity\"])\n",
    "y = df[\"is_hit\"]\n",
    "\n",
    "display(\"X shape:\", X.shape)\n",
    "display(\"X columns:\", X.columns.T)\n",
    "print(\"Distribución de y:\")\n",
    "display(y.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a6b810",
   "metadata": {},
   "source": [
    "### 3. Código: preprocesamiento (OneHot + ColumnTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0936c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Columnas numéricas:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['acousticness',\n",
       " 'danceability',\n",
       " 'duration_ms',\n",
       " 'energy',\n",
       " 'instrumentalness',\n",
       " 'liveness',\n",
       " 'loudness',\n",
       " 'speechiness',\n",
       " 'tempo',\n",
       " 'valence',\n",
       " 'beat_density',\n",
       " 'energy_valence',\n",
       " 'dance_energy',\n",
       " 'tempo_norm',\n",
       " 'loudness_norm',\n",
       " 'speech_valence',\n",
       " 'acoustic_energy',\n",
       " 'inst_energy',\n",
       " 'dance_valence',\n",
       " 'duration_min',\n",
       " 'duration_norm']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas categóricas: ['genre']\n"
     ]
    }
   ],
   "source": [
    "# Preservacion de DataFrames\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Identificación de columnas numéricas y categóricas\n",
    "numeric_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "display(\"Columnas numéricas:\", numeric_cols)\n",
    "print(\"Columnas categóricas:\", categorical_cols)\n",
    "\n",
    "# Definición del preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numeric_cols),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb158c",
   "metadata": {},
   "source": [
    "### 4. Código: modelo LightGBM + Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e101ac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Canciones clasificadas como HIT: 22346 de 232724 (9.60%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "is_hit              1.000000\n",
       "popularity          0.510005\n",
       "loudness_norm       0.150521\n",
       "loudness            0.150521\n",
       "danceability        0.150026\n",
       "dance_energy        0.139055\n",
       "energy              0.087339\n",
       "dance_valence       0.075385\n",
       "energy_valence      0.063141\n",
       "valence             0.047119\n",
       "tempo               0.031512\n",
       "tempo_norm          0.031512\n",
       "speech_valence     -0.008027\n",
       "speechiness        -0.021286\n",
       "beat_density       -0.022976\n",
       "duration_min       -0.030768\n",
       "duration_ms        -0.030768\n",
       "duration_norm      -0.030768\n",
       "liveness           -0.056944\n",
       "acoustic_energy    -0.061188\n",
       "inst_energy        -0.099680\n",
       "acousticness       -0.133575\n",
       "instrumentalness   -0.136053\n",
       "Name: is_hit, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"✅ Canciones clasificadas como HIT: {df['is_hit'].sum()} de {len(df)} ({df['is_hit'].mean()*100:.2f}%)\")\n",
    "# Correlación directa con popularidad o is_hit\n",
    "corr = df.corr(numeric_only=True)\n",
    "corr[\"is_hit\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa3747",
   "metadata": {},
   "source": [
    "### 5. Código: train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c24cef9",
   "metadata": {},
   "source": [
    "70% → train (para entrenar modelos)\n",
    "\n",
    "10% → validation (para buscar el mejor threshold)\n",
    "\n",
    "20% → test (solo para evaluar al final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315e77f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162906, 22) → train (70%)\n",
      "(23273, 22) → validation (10%)\n",
      "(46545, 22) → test (20%)\n"
     ]
    }
   ],
   "source": [
    "# 1. Split train/test (80 / 20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 2. Split interno train/val (70 / 10)\n",
    "X_trainModel, X_val, y_trainModel, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.125,        # 0.125 de 80% = 10%\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(X_trainModel.shape, \"→ train (70%)\")\n",
    "print(X_val.shape,        \"→ validation (10%)\")\n",
    "print(X_test.shape,       \"→ test (20%)\")\n",
    "\n",
    "# 3. Restaurar nombres de columnas \n",
    "X_trainModel = pd.DataFrame(X_trainModel, columns=X.columns)\n",
    "X_val        = pd.DataFrame(X_val,        columns=X.columns)\n",
    "X_test       = pd.DataFrame(X_test,       columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e63d6",
   "metadata": {},
   "source": [
    "### 6. Pipeline + Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1363596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'model__learning_rate': 0.03,\n",
       "  'model__min_child_samples': 20,\n",
       "  'model__n_estimators': 1000,\n",
       "  'model__num_leaves': 63,\n",
       "  'model__scale_pos_weight': 8},\n",
       " np.float64(0.545195596864489))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1))\n",
    "])\n",
    "param_grid = {\n",
    "    \"model__num_leaves\": [31,63],\n",
    "    \"model__learning_rate\": [0.03,0.015],\n",
    "    \"model__n_estimators\": [1000],\n",
    "    \"model__min_child_samples\": [20,50],\n",
    "    \"model__scale_pos_weight\": [8,12],\n",
    "}\n",
    "grid = GridSearchCV(pipeline, param_grid, scoring=\"f1\", cv=3, verbose=1, n_jobs=-1)\n",
    "grid.fit(X_trainModel, y_trainModel)\n",
    "grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096daae",
   "metadata": {},
   "source": [
    "### 7. Evaluación del Modelo (Threshold = 0.5 por defecto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2c3ece1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.8670\n",
      "F1-score:   0.5494\n",
      "ROC-AUC:    0.9351\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92     42076\n",
      "           1       0.41      0.84      0.55      4469\n",
      "\n",
      "    accuracy                           0.87     46545\n",
      "   macro avg       0.69      0.86      0.74     46545\n",
      "weighted avg       0.93      0.87      0.89     46545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"Accuracy:   {acc:.4f}\")\n",
    "print(f\"F1-score:   {f1:.4f}\")\n",
    "print(f\"ROC-AUC:    {auc:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7cb4d6",
   "metadata": {},
   "source": [
    "### 8. Optimización del umbral de decisión (threshold tuning - F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed77119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor threshold (val): 0.702\n",
      "Mejor F1-score (val): 0.6323\n"
     ]
    }
   ],
   "source": [
    "# 1. Probabilidades en VALIDATION usando el MEJOR MODELO\n",
    "y_proba_val = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 2. Threshold tuning usando el set de VALIDACIÓN\n",
    "thresholds = np.linspace(0.05, 0.95, 30)\n",
    "f1_scores = []\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (y_proba_val >= t).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))   \n",
    "\n",
    "best_t = thresholds[np.argmax(f1_scores)]\n",
    "best_f1 = max(f1_scores)\n",
    "\n",
    "print(f\"Mejor threshold (val): {best_t:.3f}\")\n",
    "print(f\"Mejor F1-score (val): {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce673ca",
   "metadata": {},
   "source": [
    "### 9. Evaluación final con threshold optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb56c0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Métricas con threshold optimizado (TEST) ===\n",
      "Usando threshold: 0.702\n",
      "Accuracy: 0.9257\n",
      "F1-score: 0.6216\n",
      "ROC-AUC:  0.9351\n"
     ]
    }
   ],
   "source": [
    "# 1. Probabilidades en el conjunto de TEST usando el MEJOR MODELO\n",
    "y_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 2. Aplicar threshold óptimo encontrado en VALIDATION\n",
    "y_pred_opt = (y_proba_test >= best_t).astype(int)\n",
    "\n",
    "# 3. Calcular métricas sobre TEST\n",
    "acc_opt = accuracy_score(y_test, y_pred_opt)\n",
    "f1_opt  = f1_score(y_test, y_pred_opt)\n",
    "auc_opt = roc_auc_score(y_test, y_proba_test)\n",
    "\n",
    "print(\"=== Métricas con threshold optimizado (TEST) ===\")\n",
    "print(f\"Usando threshold: {best_t:.3f}\")\n",
    "print(f\"Accuracy: {acc_opt:.4f}\")\n",
    "print(f\"F1-score: {f1_opt:.4f}\")\n",
    "print(f\"ROC-AUC:  {auc_opt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e4b00",
   "metadata": {},
   "source": [
    "### 10. Guardar Modelos Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9f171f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos X_test.csv y y_test.csv guardados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Guardar X_test y y_test para evaluación independiente\n",
    "X_test.to_csv(\"../data/processed/X_test.csv\", index=False)\n",
    "pd.DataFrame({\"is_hit\": y_test}).to_csv(\"../data/processed/y_test.csv\", index=False)\n",
    "\n",
    "print(\"Archivos X_test.csv y y_test.csv guardados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28152b03",
   "metadata": {},
   "source": [
    "### 11. Guardado del modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64426f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos guardados correctamente.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definir rutas\n",
    "MODEL_PATH_JOBLIB = \"../models/spotify_lightgbm_hit_classifier.joblib\"\n",
    "MODEL_PATH_PKL    = \"../models/spotify_lightgbm_hit_classifier.pkl\"\n",
    "\n",
    "PIPELINE_PATH_JOBLIB = \"../models/model_pipeline.joblib\"\n",
    "PIPELINE_PATH_PKL    = \"../models/model_pipeline.pkl\"\n",
    "\n",
    "# Guardar modelo\n",
    "joblib.dump(best_model, MODEL_PATH_JOBLIB)\n",
    "\n",
    "with open(MODEL_PATH_PKL, \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Guardar pipeline\n",
    "joblib.dump(pipeline, PIPELINE_PATH_JOBLIB)\n",
    "\n",
    "with open(PIPELINE_PATH_PKL, \"wb\") as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "\n",
    "print(\"Modelos guardados correctamente.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
