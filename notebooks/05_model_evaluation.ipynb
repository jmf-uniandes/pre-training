{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 05_evaluation\nEvaluaci\u00f3n final del modelo (LightGBM + threshold tuning)."]}, {"cell_type": "code", "metadata": {}, "source": ["import joblib\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report"]}, {"cell_type": "code", "metadata": {}, "source": ["# Cargar modelo y datos de prueba\n", "pipeline = joblib.load('model_pipeline.pkl')\n", "X_test = pd.read_csv('X_test.csv')\n", "y_test = pd.read_csv('y_test.csv').values.ravel()"]}, {"cell_type": "code", "metadata": {}, "source": ["# Probabilidades en TEST\n", "y_proba_test = pipeline.predict_proba(X_test)[:, 1]\n", "best_t = 0.795\n", "y_pred_opt = (y_proba_test >= best_t).astype(int)"]}, {"cell_type": "code", "metadata": {}, "source": ["# M\u00e9tricas finales\n", "acc = accuracy_score(y_test, y_pred_opt)\n", "f1 = f1_score(y_test, y_pred_opt)\n", "auc = roc_auc_score(y_test, y_proba_test)\n", "cm = confusion_matrix(y_test, y_pred_opt)\n", "print(acc, f1, auc)\n", "print(cm)\n", "print(classification_report(y_test, y_pred_opt))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}