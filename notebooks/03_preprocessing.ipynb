{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a451b4",
   "metadata": {},
   "source": [
    "# Preprocesamiento y preparación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ac1cec",
   "metadata": {},
   "source": [
    "1. Carga del dataset limpio `spotify_clean_modeling.csv`.  \n",
    "2. Separación de variables predictoras (X) y objetivo (`y = is_hit`).  \n",
    "3. Evaluación de los modelos:  \n",
    "   a. RandomForestClassifier  \n",
    "   b. GradientBoostingClassifier  \n",
    "   c. XGBoost  \n",
    "   d. LightGBM  \n",
    "   e. LogisticRegression  \n",
    "   f. KNeighborsClassifier  \n",
    "4. Escalado o normalización de variables numéricas.  \n",
    "5. División del conjunto en entrenamiento y prueba (`train_test_split`).  \n",
    "6. Guardado de los datos procesados (`X_train`, `X_test`, `y_train`, `y_test`).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31f1534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset se ha cargado correctamente en un arreglo: (232724, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['genre', 'popularity', 'acousticness', 'danceability', 'duration_ms',\n",
       "       'energy', 'instrumentalness', 'liveness', 'loudness', 'mode',\n",
       "       'speechiness', 'tempo', 'time_signature', 'valence', 'is_hit'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.389</td>\n",
       "      <td>99373</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>-1.828</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>166.969</td>\n",
       "      <td>4</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.590</td>\n",
       "      <td>137373</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-5.559</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>174.003</td>\n",
       "      <td>4</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Movie</td>\n",
       "      <td>3</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.663</td>\n",
       "      <td>170267</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>-13.879</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>99.488</td>\n",
       "      <td>5</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.240</td>\n",
       "      <td>152427</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>-12.178</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>171.758</td>\n",
       "      <td>4</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Movie</td>\n",
       "      <td>4</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.331</td>\n",
       "      <td>82625</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>-21.150</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>140.576</td>\n",
       "      <td>4</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre  popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0  Movie           0         0.611         0.389        99373   0.910   \n",
       "1  Movie           1         0.246         0.590       137373   0.737   \n",
       "2  Movie           3         0.952         0.663       170267   0.131   \n",
       "3  Movie           0         0.703         0.240       152427   0.326   \n",
       "4  Movie           4         0.950         0.331        82625   0.225   \n",
       "\n",
       "   instrumentalness  liveness  loudness  mode  speechiness    tempo  \\\n",
       "0             0.000    0.3460    -1.828     1       0.0525  166.969   \n",
       "1             0.000    0.1510    -5.559     0       0.0868  174.003   \n",
       "2             0.000    0.1030   -13.879     0       0.0362   99.488   \n",
       "3             0.000    0.0985   -12.178     1       0.0395  171.758   \n",
       "4             0.123    0.2020   -21.150     1       0.0456  140.576   \n",
       "\n",
       "   time_signature  valence  is_hit  \n",
       "0               4    0.814       0  \n",
       "1               4    0.816       0  \n",
       "2               5    0.368       0  \n",
       "3               4    0.227       0  \n",
       "4               4    0.390       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Ruta al archivo fuente inicial \n",
    "DATA_PATH = \"../data/processed/spotify_clean_modeling.csv\"\n",
    "\n",
    "# Verificar existencia\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"No se encontró el archivo en {DATA_PATH}\")\n",
    "\n",
    "# Carga el archivo CSV\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Dataset se ha cargado correctamente en un arreglo: {df.shape}\")\n",
    "\n",
    "display(df.columns.T)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a147a5c",
   "metadata": {},
   "source": [
    "## Normalizacion duration_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44031b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizacion Duracion\n",
    "df[\"duration_min\"] = df[\"duration_ms\"] / 60000\n",
    "df.drop(columns=\"duration_ms\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f65f9b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Canciones clasificadas como HIT: 10544 de 232724 (4.53%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "is_hit              1.000000\n",
       "popularity          0.391859\n",
       "danceability        0.121247\n",
       "loudness            0.108466\n",
       "energy              0.061671\n",
       "valence             0.037736\n",
       "time_signature      0.037443\n",
       "tempo               0.022765\n",
       "speechiness        -0.008862\n",
       "mode               -0.019692\n",
       "duration_min       -0.023957\n",
       "liveness           -0.043567\n",
       "acousticness       -0.094851\n",
       "instrumentalness   -0.097980\n",
       "Name: is_hit, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"✅ Canciones clasificadas como HIT: {df['is_hit'].sum()} de {len(df)} ({df['is_hit'].mean()*100:.2f}%)\")\n",
    "# Correlación directa con popularidad o is_hit\n",
    "corr = df.corr(numeric_only=True)\n",
    "corr[\"is_hit\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704c99c6",
   "metadata": {},
   "source": [
    "Se encuentra un desbalance de los datos solo 4.53% representan hits, lo que nos hace notar que solo tener un buen accuracy (Predicciones Correctas) no\n",
    "es suficiente, para el modelo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12bf34",
   "metadata": {},
   "source": [
    "## Separación de variables predictoras (X) y objetivo (y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68742ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=[\"is_hit\",\"popularity\"])\n",
    "\n",
    "y = df[\"is_hit\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c8b52",
   "metadata": {},
   "source": [
    "## Creación de DataFrames para Codificar Variabls Categóricas y Entrenamiento de Modelos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b56a838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para modelos de árboles → LabelEncoder\n",
    "X_tree = X.copy()\n",
    "le = LabelEncoder()\n",
    "X_tree[\"genre\"] = le.fit_transform(X_tree[\"genre\"])\n",
    "\n",
    "# Para modelos lineales / distancia → OneHotEncoder\n",
    "preprocessor_ohe = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"genre\"])\n",
    "], remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77f3e683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre                 int64\n",
       "acousticness        float64\n",
       "danceability        float64\n",
       "energy              float64\n",
       "instrumentalness    float64\n",
       "liveness            float64\n",
       "loudness            float64\n",
       "mode                  int64\n",
       "speechiness         float64\n",
       "tempo               float64\n",
       "time_signature        int64\n",
       "valence             float64\n",
       "duration_min        float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>232724.000000</td>\n",
       "      <td>232724.000000</td>\n",
       "      <td>232724.000000</td>\n",
       "      <td>232724.000000</td>\n",
       "      <td>232724.000000</td>\n",
       "      <td>232724.000000</td>\n",
       "      <td>232724.000000</td>\n",
       "      <td>232724.000000</td>\n",
       "      <td>232724.000000</td>\n",
       "      <td>232724.000000</td>\n",
       "      <td>232724.000000</td>\n",
       "      <td>232724.000000</td>\n",
       "      <td>232724.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.623270</td>\n",
       "      <td>0.368562</td>\n",
       "      <td>0.554366</td>\n",
       "      <td>0.570958</td>\n",
       "      <td>0.148302</td>\n",
       "      <td>0.215010</td>\n",
       "      <td>-9.569896</td>\n",
       "      <td>0.652030</td>\n",
       "      <td>0.120765</td>\n",
       "      <td>117.666494</td>\n",
       "      <td>3.885147</td>\n",
       "      <td>0.454919</td>\n",
       "      <td>3.918697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.491218</td>\n",
       "      <td>0.354768</td>\n",
       "      <td>0.185608</td>\n",
       "      <td>0.263456</td>\n",
       "      <td>0.302769</td>\n",
       "      <td>0.198273</td>\n",
       "      <td>5.998215</td>\n",
       "      <td>0.476328</td>\n",
       "      <td>0.185519</td>\n",
       "      <td>30.898942</td>\n",
       "      <td>0.462956</td>\n",
       "      <td>0.260065</td>\n",
       "      <td>1.982265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>-52.457000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>30.379000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>-11.771000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>92.959000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>3.047604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>-7.762000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>115.777500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>3.673783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>-5.501000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>139.054500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>4.429467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.744000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>242.903000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>92.548617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               genre   acousticness   danceability         energy  \\\n",
       "count  232724.000000  232724.000000  232724.000000  232724.000000   \n",
       "mean       13.623270       0.368562       0.554366       0.570958   \n",
       "std         7.491218       0.354768       0.185608       0.263456   \n",
       "min         0.000000       0.000000       0.056900       0.000020   \n",
       "25%         7.000000       0.037600       0.435000       0.385000   \n",
       "50%        14.000000       0.232000       0.571000       0.605000   \n",
       "75%        20.000000       0.722000       0.692000       0.787000   \n",
       "max        26.000000       0.996000       0.989000       0.999000   \n",
       "\n",
       "       instrumentalness       liveness       loudness           mode  \\\n",
       "count     232724.000000  232724.000000  232724.000000  232724.000000   \n",
       "mean           0.148302       0.215010      -9.569896       0.652030   \n",
       "std            0.302769       0.198273       5.998215       0.476328   \n",
       "min            0.000000       0.009670     -52.457000       0.000000   \n",
       "25%            0.000000       0.097400     -11.771000       0.000000   \n",
       "50%            0.000044       0.128000      -7.762000       1.000000   \n",
       "75%            0.035800       0.264000      -5.501000       1.000000   \n",
       "max            0.999000       1.000000       3.744000       1.000000   \n",
       "\n",
       "         speechiness          tempo  time_signature        valence  \\\n",
       "count  232724.000000  232724.000000   232724.000000  232724.000000   \n",
       "mean        0.120765     117.666494        3.885147       0.454919   \n",
       "std         0.185519      30.898942        0.462956       0.260065   \n",
       "min         0.022200      30.379000        0.000000       0.000000   \n",
       "25%         0.036700      92.959000        4.000000       0.237000   \n",
       "50%         0.050100     115.777500        4.000000       0.444000   \n",
       "75%         0.105000     139.054500        4.000000       0.660000   \n",
       "max         0.967000     242.903000        5.000000       1.000000   \n",
       "\n",
       "        duration_min  \n",
       "count  232724.000000  \n",
       "mean        3.918697  \n",
       "std         1.982265  \n",
       "min         0.256450  \n",
       "25%         3.047604  \n",
       "50%         3.673783  \n",
       "75%         4.429467  \n",
       "max        92.548617  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(X_tree.dtypes)\n",
    "\n",
    "X_tree.describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52185733",
   "metadata": {},
   "source": [
    "## Division de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0daafb",
   "metadata": {},
   "source": [
    "### División en entrenamiento y prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70705a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tree, X_test_tree, y_train, y_test = train_test_split(X_tree, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a713cb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>13.617218</td>\n",
       "      <td>7.486709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acousticness</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>0.368902</td>\n",
       "      <td>0.354867</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>0.72200</td>\n",
       "      <td>0.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>0.554477</td>\n",
       "      <td>0.185612</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>0.69200</td>\n",
       "      <td>0.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>0.570743</td>\n",
       "      <td>0.263453</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.78700</td>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumentalness</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>0.148567</td>\n",
       "      <td>0.303068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.03590</td>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveness</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>0.215131</td>\n",
       "      <td>0.198184</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.26400</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>-9.572569</td>\n",
       "      <td>5.999228</td>\n",
       "      <td>-52.457000</td>\n",
       "      <td>-11.779000</td>\n",
       "      <td>-7.762000</td>\n",
       "      <td>-5.50200</td>\n",
       "      <td>3.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>0.651701</td>\n",
       "      <td>0.476433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechiness</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>0.120547</td>\n",
       "      <td>0.185210</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.10500</td>\n",
       "      <td>0.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>117.667631</td>\n",
       "      <td>30.906681</td>\n",
       "      <td>30.379000</td>\n",
       "      <td>92.938000</td>\n",
       "      <td>115.836000</td>\n",
       "      <td>139.09000</td>\n",
       "      <td>242.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_signature</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>3.885180</td>\n",
       "      <td>0.463138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>0.455087</td>\n",
       "      <td>0.260007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.66000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_min</th>\n",
       "      <td>186179.0</td>\n",
       "      <td>3.918045</td>\n",
       "      <td>1.995963</td>\n",
       "      <td>0.256450</td>\n",
       "      <td>3.046225</td>\n",
       "      <td>3.671850</td>\n",
       "      <td>4.42695</td>\n",
       "      <td>92.548617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count        mean        std        min        25%  \\\n",
       "genre             186179.0   13.617218   7.486709   0.000000   7.000000   \n",
       "acousticness      186179.0    0.368902   0.354867   0.000001   0.037600   \n",
       "danceability      186179.0    0.554477   0.185612   0.056900   0.435000   \n",
       "energy            186179.0    0.570743   0.263453   0.000020   0.385000   \n",
       "instrumentalness  186179.0    0.148567   0.303068   0.000000   0.000000   \n",
       "liveness          186179.0    0.215131   0.198184   0.009670   0.097400   \n",
       "loudness          186179.0   -9.572569   5.999228 -52.457000 -11.779000   \n",
       "mode              186179.0    0.651701   0.476433   0.000000   0.000000   \n",
       "speechiness       186179.0    0.120547   0.185210   0.022200   0.036700   \n",
       "tempo             186179.0  117.667631  30.906681  30.379000  92.938000   \n",
       "time_signature    186179.0    3.885180   0.463138   0.000000   4.000000   \n",
       "valence           186179.0    0.455087   0.260007   0.000000   0.238000   \n",
       "duration_min      186179.0    3.918045   1.995963   0.256450   3.046225   \n",
       "\n",
       "                         50%        75%         max  \n",
       "genre              14.000000   20.00000   26.000000  \n",
       "acousticness        0.233000    0.72200    0.996000  \n",
       "danceability        0.571000    0.69200    0.989000  \n",
       "energy              0.605000    0.78700    0.999000  \n",
       "instrumentalness    0.000045    0.03590    0.999000  \n",
       "liveness            0.128000    0.26400    1.000000  \n",
       "loudness           -7.762000   -5.50200    3.744000  \n",
       "mode                1.000000    1.00000    1.000000  \n",
       "speechiness         0.050100    0.10500    0.967000  \n",
       "tempo             115.836000  139.09000  242.903000  \n",
       "time_signature      4.000000    4.00000    5.000000  \n",
       "valence             0.444000    0.66000    1.000000  \n",
       "duration_min        3.671850    4.42695   92.548617  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tree.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d861488a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25,  9,  6,  8, 14, 23, 17, 22, 24,  4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tree[\"genre\"].unique()[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1358b59",
   "metadata": {},
   "source": [
    "## Definicion de Modelos Dinamico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381ba2ad",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "\n",
    "Modelo lineal.\n",
    "Sirve como baseline. Rápido, interpretable y muestra qué variables empujan a la probabilidad de ser hit.\n",
    "\n",
    "2. Random Forest\n",
    "\n",
    "Ensamble de muchos árboles de decisión.\n",
    "Robusto, maneja no-linealidades y detecta interacciones entre features automáticamente.\n",
    "\n",
    "3. Gradient Boosting (GBM clásico de sklearn)\n",
    "\n",
    "Construye árboles de manera secuencial, corrigiendo errores del anterior.\n",
    "Mejor rendimiento que RandomForest pero más lento.\n",
    "\n",
    "4. XGBoost\n",
    "\n",
    "Implementación optimizada y más poderosa de boosting.\n",
    "Alta precisión, muy usado en competencias de Kaggle. Excelente con datasets tabulares.\n",
    "\n",
    "5. LightGBM\n",
    "\n",
    "Boosting muy rápido desarrollado por Microsoft.\n",
    "Funciona excelente con grandes volúmenes (como tu dataset de 230k filas).\n",
    "Suele superar a XGBoost en velocidad con rendimiento similar o mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b601d03c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 101\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# EJECUTAR TODOS LOS BATCHES\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nombre_batch, config \u001b[38;5;129;01min\u001b[39;00m batches.items():\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     resultados_globales.extend(\u001b[43mentrenar_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnombre_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# RESULTADOS COMBINADOS\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m    107\u001b[39m df_resultados = pd.DataFrame(resultados_globales).sort_values(by=[\u001b[33m\"\u001b[39m\u001b[33mBatch\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mF1\u001b[39m\u001b[33m\"\u001b[39m], ascending=[\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mentrenar_batch\u001b[39m\u001b[34m(nombre_batch, config_batch)\u001b[39m\n\u001b[32m     44\u001b[39m tree_models = {\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRandomForest\u001b[39m\u001b[33m\"\u001b[39m: RandomForestClassifier(n_jobs=-\u001b[32m1\u001b[39m, random_state=\u001b[32m42\u001b[39m, class_weight=\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, **config_batch[\u001b[33m\"\u001b[39m\u001b[33mRandomForest\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m     46\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mGradientBoosting\u001b[39m\u001b[33m\"\u001b[39m: GradientBoostingClassifier(random_state=\u001b[32m42\u001b[39m, **config_batch[\u001b[33m\"\u001b[39m\u001b[33mGradientBoosting\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     )\n\u001b[32m     60\u001b[39m }\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nombre, modelo \u001b[38;5;129;01min\u001b[39;00m tree_models.items():\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[43mmodelo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     y_pred = modelo.predict(X_test_tree)\n\u001b[32m     65\u001b[39m     resultados.append({\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBatch\u001b[39m\u001b[33m\"\u001b[39m: nombre_batch,\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mModelo\u001b[39m\u001b[33m\"\u001b[39m: nombre,\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mROC_AUC\u001b[39m\u001b[33m\"\u001b[39m: roc_auc_score(y_test, y_pred)\n\u001b[32m     71\u001b[39m     })\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\UniAndes\\Seminario\\pre-training\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\UniAndes\\Seminario\\pre-training\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:787\u001b[39m, in \u001b[36mBaseGradientBoosting.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, monitor)\u001b[39m\n\u001b[32m    784\u001b[39m     \u001b[38;5;28mself\u001b[39m._resize_state()\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m n_stages = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_stages != \u001b[38;5;28mself\u001b[39m.estimators_.shape[\u001b[32m0\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\UniAndes\\Seminario\\pre-training\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:883\u001b[39m, in \u001b[36mBaseGradientBoosting._fit_stages\u001b[39m\u001b[34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[39m\n\u001b[32m    876\u001b[39m         initial_loss = factor * \u001b[38;5;28mself\u001b[39m._loss(\n\u001b[32m    877\u001b[39m             y_true=y_oob_masked,\n\u001b[32m    878\u001b[39m             raw_prediction=raw_predictions[~sample_mask],\n\u001b[32m    879\u001b[39m             sample_weight=sample_weight_oob_masked,\n\u001b[32m    880\u001b[39m         )\n\u001b[32m    882\u001b[39m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m883\u001b[39m raw_predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\UniAndes\\Seminario\\pre-training\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:489\u001b[39m, in \u001b[36mBaseGradientBoosting._fit_stage\u001b[39m\u001b[34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[39m\n\u001b[32m    486\u001b[39m     sample_weight = sample_weight * sample_mask.astype(np.float64)\n\u001b[32m    488\u001b[39m X = X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_g_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[32m    494\u001b[39m X_for_tree_update = X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\UniAndes\\Seminario\\pre-training\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\UniAndes\\Seminario\\pre-training\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1404\u001b[39m, in \u001b[36mDecisionTreeRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m   1374\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1375\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, check_input=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1376\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[32m   1377\u001b[39m \n\u001b[32m   1378\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1401\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m   1402\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1404\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1410\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\UniAndes\\Seminario\\pre-training\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# CONFIGURACIÓN GENERAL\n",
    "# ===============================\n",
    "\n",
    "# Calcular peso de clase positiva (para XGBoost)\n",
    "pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# Colección para guardar resultados de todos los experimentos\n",
    "resultados_globales = []\n",
    "\n",
    "# ===============================\n",
    "# DEFINIR BATCHES DE EXPERIMENTOS\n",
    "# ===============================\n",
    "\n",
    "batch_1 = {\n",
    "    \"RandomForest\": {\"n_estimators\": 300, \"max_depth\": None, \"min_samples_leaf\": 2},\n",
    "    \"GradientBoosting\": {\"n_estimators\": 400, \"learning_rate\": 0.05, \"max_depth\": 5},\n",
    "    \"XGBoost\": {\"n_estimators\": 600, \"learning_rate\": 0.05, \"max_depth\": 6},\n",
    "    \"LightGBM\": {\"n_estimators\": 600, \"num_leaves\": 64, \"learning_rate\": 0.03},\n",
    "    \"LogisticRegression\": {\"max_iter\": 1000, \"solver\": \"liblinear\"},\n",
    "    \"KNeighbors\": {\"n_neighbors\": 10, \"weights\": \"distance\"}\n",
    "}\n",
    "\n",
    "batch_2 = {\n",
    "    \"RandomForest\": {\"n_estimators\": 800, \"max_depth\": 10, \"min_samples_leaf\": 1},\n",
    "    \"GradientBoosting\": {\"n_estimators\": 800, \"learning_rate\": 0.02, \"max_depth\": 6},\n",
    "    \"XGBoost\": {\"n_estimators\": 1000, \"learning_rate\": 0.03, \"max_depth\": 8},\n",
    "    \"LightGBM\": {\"n_estimators\": 1000, \"num_leaves\": 128, \"learning_rate\": 0.02},\n",
    "    \"LogisticRegression\": {\"max_iter\": 2000, \"solver\": \"liblinear\"},\n",
    "    \"KNeighbors\": {\"n_neighbors\": 20, \"weights\": \"uniform\"}\n",
    "}\n",
    "\n",
    "# Puedes agregar batch_3, batch_4, etc.\n",
    "batches = {\"Batch_1\": batch_1, \"Batch_2\": batch_2}\n",
    "\n",
    "# ===============================\n",
    "# FUNCIÓN PARA EJECUTAR UN BATCH\n",
    "# ===============================\n",
    "\n",
    "def entrenar_batch(nombre_batch, config_batch):\n",
    "    resultados = []\n",
    "\n",
    "    # Modelos tipo árbol\n",
    "    tree_models = {\n",
    "        \"RandomForest\": RandomForestClassifier(n_jobs=-1, random_state=42, class_weight=\"balanced\", **config_batch[\"RandomForest\"]),\n",
    "        \"GradientBoosting\": GradientBoostingClassifier(random_state=42, **config_batch[\"GradientBoosting\"]),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            n_jobs=-1,\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42,\n",
    "            scale_pos_weight=pos_weight,\n",
    "            **config_batch[\"XGBoost\"]\n",
    "        ),\n",
    "        \"LightGBM\": LGBMClassifier(\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced\",\n",
    "            **config_batch[\"LightGBM\"]\n",
    "        )\n",
    "    }\n",
    "\n",
    "    for nombre, modelo in tree_models.items():\n",
    "        modelo.fit(X_train_tree, y_train)\n",
    "        y_pred = modelo.predict(X_test_tree)\n",
    "        resultados.append({\n",
    "            \"Batch\": nombre_batch,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"F1\": f1_score(y_test, y_pred),\n",
    "            \"ROC_AUC\": roc_auc_score(y_test, y_pred)\n",
    "        })\n",
    "\n",
    "    # Modelos lineales / distancia\n",
    "    linear_models = {\n",
    "        \"LogisticRegression\": LogisticRegression(class_weight=\"balanced\", **config_batch[\"LogisticRegression\"]),\n",
    "        \"KNeighbors\": KNeighborsClassifier(n_jobs=-1, **config_batch[\"KNeighbors\"])\n",
    "    }\n",
    "\n",
    "    for nombre, modelo in linear_models.items():\n",
    "        clf = Pipeline(steps=[\n",
    "            (\"preprocess\", preprocessor_ohe),\n",
    "            (\"model\", modelo)\n",
    "        ])\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        resultados.append({\n",
    "            \"Batch\": nombre_batch,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"F1\": f1_score(y_test, y_pred),\n",
    "            \"ROC_AUC\": roc_auc_score(y_test, y_pred)\n",
    "        })\n",
    "\n",
    "    return resultados\n",
    "\n",
    "# ===============================\n",
    "# EJECUTAR TODOS LOS BATCHES\n",
    "# ===============================\n",
    "\n",
    "for nombre_batch, config in batches.items():\n",
    "    resultados_globales.extend(entrenar_batch(nombre_batch, config))\n",
    "\n",
    "# ===============================\n",
    "# RESULTADOS COMBINADOS\n",
    "# ===============================\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados_globales).sort_values(by=[\"Batch\", \"F1\"], ascending=[True, False])\n",
    "display(df_resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b0074",
   "metadata": {},
   "source": [
    "## Tabla de resultados ordenada por Modelo y Accuracy para cada batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72001e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ordenado = (\n",
    "    df_resultados\n",
    "        .sort_values(by=[\"Modelo\", \"Accuracy\"], ascending=[True, False])\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "display(df_ordenado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94640cc0",
   "metadata": {},
   "source": [
    "# Interpretacion de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    df_resultados\n",
    "        .query(\"Modelo == 'GradientBoosting'\")\n",
    "        .sort_values(by=\"Accuracy\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645a906",
   "metadata": {},
   "source": [
    "Interpretación:\n",
    "\n",
    "Accuracy alto (95%) = engañoso por el desbalance.\n",
    "\n",
    "F1 muy bajo (12–13%) → no logra detectar hits.\n",
    "\n",
    "AUC ≈ 0.53 → apenas mejor que azar.\n",
    "\n",
    "👉 Conclusión: GradientBoosting es malo para este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac604e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    df_resultados\n",
    "        .query(\"Modelo == 'KNeighbors'\")\n",
    "        .sort_values(by=\"Accuracy\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d42468f",
   "metadata": {},
   "source": [
    "Interpretación:\n",
    "\n",
    "Comportamiento totalmente inestable.\n",
    "\n",
    "F1 pésimo (especialmente Batch_2).\n",
    "\n",
    "AUC ≈ 0.51 → casi aleatorio.\n",
    "\n",
    "👉 Conclusión: KNN no sirve en absoluto para este dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    df_resultados\n",
    "        .query(\"Modelo == 'LightGBM'\")\n",
    "        .sort_values(by=\"Accuracy\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378cf6b3",
   "metadata": {},
   "source": [
    "Interpretación:\n",
    "\n",
    "F1 de 0.51 en Batch_2 → muy bueno dada la clase minoritaria.\n",
    "\n",
    "ROC-AUC 0.89 → Excelente capacidad de separar hits de no-hits.\n",
    "\n",
    "Mucho mejor que cualquier otro.\n",
    "\n",
    "👉 Conclusión:\n",
    "LightGBM es el mejor modelo general (F1 y AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23350915",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    df_resultados\n",
    "        .query(\"Modelo == 'LogisticRegression'\")\n",
    "        .sort_values(by=\"Accuracy\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e279b0",
   "metadata": {},
   "source": [
    "Interpretación:\n",
    "\n",
    "Muy consistente entre lotes.\n",
    "\n",
    "Accuracy bajo → normal en modelos lineales.\n",
    "\n",
    "F1 promedio (0.26) → mejor que GBM clásico y KNN.\n",
    "\n",
    "ROC-AUC 0.81 → bastante bueno.\n",
    "\n",
    "👉 Conclusión:\n",
    "Modelo simple pero bien alineado con el problema. Bueno como baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    df_resultados\n",
    "        .query(\"Modelo == 'RandomForest'\")\n",
    "        .sort_values(by=\"Accuracy\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b626584e",
   "metadata": {},
   "source": [
    "Interpretación:\n",
    "\n",
    "Batch_1 y Batch_2 tienen comportamientos muy distintos.\n",
    "\n",
    "Batch_1 tiene accuracy inflado por el desbalance.\n",
    "\n",
    "Batch_2 tiene mejor AUC pero menor F1.\n",
    "\n",
    "👉 Conclusión:\n",
    "RandomForest es inestable y peor que LightGBM/XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    df_resultados\n",
    "        .query(\"Modelo == 'XGBoost'\")\n",
    "        .sort_values(by=\"Accuracy\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9d870",
   "metadata": {},
   "source": [
    "Interpretación:\n",
    "\n",
    "Muy parecido a LightGBM.\n",
    "\n",
    "F1 excelente (0.49 en Batch_2).\n",
    "\n",
    "ROC-AUC muy alto (0.88).\n",
    "\n",
    "👉 Conclusión:\n",
    "Segundo mejor modelo después de LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504788f2",
   "metadata": {},
   "source": [
    "## Resumen de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb88e3",
   "metadata": {},
   "source": [
    "Mejores modelos (claramente)\n",
    "\n",
    "LightGBM\n",
    "\n",
    "XGBoost\n",
    "Ambos alcanzan:\n",
    "\n",
    "F1 > 0.49\n",
    "\n",
    "AUC > 0.86\n",
    "\n",
    "Son consistentes y robustos en datasets grandes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch1 = df_resultados[df_resultados[\"Batch\"] == \"Batch_1\"]\n",
    "df_batch1.plot(\n",
    "    x=\"Modelo\",\n",
    "    y=[\"Accuracy\", \"F1\", \"ROC_AUC\"],\n",
    "    kind=\"bar\",\n",
    "    figsize=(10,5)\n",
    ")\n",
    "plt.title(\"Comparación de modelos – Predicción de 'Hit' (Batch 1)\")\n",
    "plt.ylabel(\"Puntaje\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8384e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch2 = df_resultados[df_resultados[\"Batch\"] == \"Batch_2\"]\n",
    "df_batch2.plot(\n",
    "    x=\"Modelo\",\n",
    "    y=[\"Accuracy\", \"F1\", \"ROC_AUC\"],\n",
    "    kind=\"bar\",\n",
    "    figsize=(10,5)\n",
    ")\n",
    "plt.title(\"Comparación de modelos – Predicción de 'Hit' (Batch 2)\")\n",
    "plt.ylabel(\"Puntaje\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf6a60",
   "metadata": {},
   "source": [
    "## Comparacion de F1-Score Bacth1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=df_resultados, x=\"Modelo\", y=\"F1\", hue=\"Batch\")\n",
    "plt.title(\"Comparación de F1-score por modelo y batch\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=df_resultados, x=\"Modelo\", y=\"ROC_AUC\", hue=\"Batch\")\n",
    "plt.title(\"Comparación de ROC_AUC por modelo y batch\")\n",
    "plt.ylabel(\"ROC_AUC\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa58e8d",
   "metadata": {},
   "source": [
    "## Seleccion de Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f1760",
   "metadata": {},
   "source": [
    "Basados en los resultados que hemos encontrado usaremos el modelo LightGBM (LGBMClassifier)\n",
    "1. Mejor F1-score\n",
    "\n",
    "Es la métrica más importante porque tu dataset está muy desbalanceado (4.6% hits).\n",
    "\n",
    "Batch 2:\n",
    "\n",
    "F1 = 0.5136\n",
    "\n",
    "El más alto de todos los modelos\n",
    "\n",
    "Detecta hits mucho mejor que XGBoost, LogisticRegression o RandomForest\n",
    "\n",
    "2. Mejor ROC-AUC o casi igual al mejor\n",
    "\n",
    "Batch 2:\n",
    "\n",
    "AUC = 0.8908\n",
    "\n",
    "Excelente separación entre hits y no-hits\n",
    "\n",
    "XGBoost tiene 0.8867, casi igual, pero F1 más bajo\n",
    "\n",
    "3. Consistente entre Batch_1 y Batch_2\n",
    "\n",
    "En ambos aparece como el mejor o muy cercano al mejor.\n",
    "\n",
    "4. Rendimiento superior en datasets grandes\n",
    "\n",
    "Tu dataset tiene 232,724 canciones\n",
    "LightGBM está diseñado para:\n",
    "\n",
    "datasets grandes\n",
    "\n",
    "alta dimensionalidad\n",
    "\n",
    "operaciones rápidas\n",
    "\n",
    "desbalance de clases con parámetros integrados\n",
    "\n",
    "5. Menor riesgo de overfitting que XGBoost\n",
    "\n",
    "XGBoost rinde muy bien, pero LightGBM tiende a generalizar mejor en escenarios como este."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
