{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a451b4",
   "metadata": {},
   "source": [
    "# Preprocesamiento y preparaci√≥n del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ac1cec",
   "metadata": {},
   "source": [
    "1. Carga del dataset limpio `spotify_clean_modeling.csv`.  \n",
    "2. Separaci√≥n de variables predictoras (X) y objetivo (`y = is_hit`).  \n",
    "3. Evaluaci√≥n de los modelos:  \n",
    "   a. RandomForestClassifier  \n",
    "   b. GradientBoostingClassifier  \n",
    "   c. XGBoost  \n",
    "   d. LightGBM  \n",
    "   e. LogisticRegression  \n",
    "   f. KNeighborsClassifier  \n",
    "4. Escalado o normalizaci√≥n de variables num√©ricas.  \n",
    "5. Divisi√≥n del conjunto en entrenamiento y prueba (`train_test_split`).  \n",
    "6. Guardado de los datos procesados (`X_train`, `X_test`, `y_train`, `y_test`).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "31f1534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset se ha cargado correctamente en un arreglo: (232724, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['genre', 'popularity', 'acousticness', 'danceability', 'duration_ms',\n",
       "       'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness',\n",
       "       'tempo', 'valence', 'is_hit'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.389</td>\n",
       "      <td>99373</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>-1.828</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>166.969</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.590</td>\n",
       "      <td>137373</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-5.559</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>174.003</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Movie</td>\n",
       "      <td>3</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.663</td>\n",
       "      <td>170267</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>-13.879</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>99.488</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.240</td>\n",
       "      <td>152427</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>-12.178</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>171.758</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Movie</td>\n",
       "      <td>4</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.331</td>\n",
       "      <td>82625</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>-21.150</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>140.576</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre  popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0  Movie           0         0.611         0.389        99373   0.910   \n",
       "1  Movie           1         0.246         0.590       137373   0.737   \n",
       "2  Movie           3         0.952         0.663       170267   0.131   \n",
       "3  Movie           0         0.703         0.240       152427   0.326   \n",
       "4  Movie           4         0.950         0.331        82625   0.225   \n",
       "\n",
       "   instrumentalness  liveness  loudness  speechiness    tempo  valence  is_hit  \n",
       "0             0.000    0.3460    -1.828       0.0525  166.969    0.814       0  \n",
       "1             0.000    0.1510    -5.559       0.0868  174.003    0.816       0  \n",
       "2             0.000    0.1030   -13.879       0.0362   99.488    0.368       0  \n",
       "3             0.000    0.0985   -12.178       0.0395  171.758    0.227       0  \n",
       "4             0.123    0.2020   -21.150       0.0456  140.576    0.390       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Ruta al archivo fuente inicial \n",
    "DATA_PATH = \"../data/processed/spotify_clean_modeling.csv\"\n",
    "\n",
    "# Verificar existencia\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"No se encontr√≥ el archivo en {DATA_PATH}\")\n",
    "\n",
    "# Carga el archivo CSV\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Dataset se ha cargado correctamente en un arreglo: {df.shape}\")\n",
    "\n",
    "display(df.columns.T)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6533da2e",
   "metadata": {},
   "source": [
    "## Creacion Nuevas Caracteristicas y Normalizacion de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "611c8d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevas caracter√≠sticas creadas:\n",
      "- duration_min\n",
      "- beat_density\n",
      "- energy_valence\n",
      "- dance_energy\n",
      "- speech_valence\n",
      "- acoustic_energy\n",
      "- inst_energy\n",
      "- dance_valence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_min</th>\n",
       "      <th>beat_density</th>\n",
       "      <th>energy_valence</th>\n",
       "      <th>dance_energy</th>\n",
       "      <th>speech_valence</th>\n",
       "      <th>acoustic_energy</th>\n",
       "      <th>inst_energy</th>\n",
       "      <th>dance_valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.656217</td>\n",
       "      <td>100.813501</td>\n",
       "      <td>0.740740</td>\n",
       "      <td>0.353990</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.556010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.289550</td>\n",
       "      <td>75.998777</td>\n",
       "      <td>0.601392</td>\n",
       "      <td>0.434830</td>\n",
       "      <td>0.070829</td>\n",
       "      <td>0.181302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.837783</td>\n",
       "      <td>35.058350</td>\n",
       "      <td>0.048208</td>\n",
       "      <td>0.086853</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>0.124712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.540450</td>\n",
       "      <td>67.609282</td>\n",
       "      <td>0.074002</td>\n",
       "      <td>0.078240</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>0.229178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.377083</td>\n",
       "      <td>102.082421</td>\n",
       "      <td>0.087750</td>\n",
       "      <td>0.074475</td>\n",
       "      <td>0.017784</td>\n",
       "      <td>0.213750</td>\n",
       "      <td>0.027675</td>\n",
       "      <td>0.129090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration_min  beat_density  energy_valence  dance_energy  speech_valence  \\\n",
       "0      1.656217    100.813501        0.740740      0.353990        0.042735   \n",
       "1      2.289550     75.998777        0.601392      0.434830        0.070829   \n",
       "2      2.837783     35.058350        0.048208      0.086853        0.013322   \n",
       "3      2.540450     67.609282        0.074002      0.078240        0.008967   \n",
       "4      1.377083    102.082421        0.087750      0.074475        0.017784   \n",
       "\n",
       "   acoustic_energy  inst_energy  dance_valence  \n",
       "0         0.556010     0.000000       0.316646  \n",
       "1         0.181302     0.000000       0.481440  \n",
       "2         0.124712     0.000000       0.243984  \n",
       "3         0.229178     0.000000       0.054480  \n",
       "4         0.213750     0.027675       0.129090  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalizaci√≥n de Duraci√≥n\n",
    "\n",
    "df[\"duration_min\"] = df[\"duration_ms\"] / 60000\n",
    "\n",
    "df.drop(columns=[\"duration_ms\"],errors='ignore', inplace=True)\n",
    "\n",
    "# 1. Ritmo percibido real\n",
    "# Mide cu√°ntos \"beats por minuto real\" tiene la canci√≥n relativo a su duraci√≥n.\n",
    "df[\"beat_density\"] = df[\"tempo\"] / df[\"duration_min\"]\n",
    "\n",
    "# 2. Energ√≠a emocional\n",
    "# Captura qu√© tan intensa y emocionalmente positiva es la canci√≥n a la vez.\n",
    "df[\"energy_valence\"] = df[\"energy\"] * df[\"valence\"]\n",
    "\n",
    "# 3. Intensidad bailable\n",
    "# Representa cu√°nta energ√≠a tiene la canci√≥n mientras sigue siendo bailable.\n",
    "df[\"dance_energy\"] = df[\"danceability\"] * df[\"energy\"]\n",
    "\n",
    "# 4. Combinaciones adicionales \n",
    "# speech_valence ‚Üí mide cu√°n \"feliz\" es una canci√≥n hablada o con estilo rap.\n",
    "df[\"speech_valence\"] = df[\"speechiness\"] * df[\"valence\"]\n",
    "\n",
    "# acoustic_energy ‚Üí mide cu√°nta energ√≠a tiene una canci√≥n ac√∫stica o con instrumentos reales.\n",
    "df[\"acoustic_energy\"] = df[\"acousticness\"] * df[\"energy\"]\n",
    "\n",
    "# inst_energy ‚Üí mide la intensidad de canciones instrumentales, especialmente EDM o techno.\n",
    "df[\"inst_energy\"] = df[\"instrumentalness\"] * df[\"energy\"]\n",
    "\n",
    "# dance_valence ‚Üí mide qu√© tan bailable y emocionalmente positiva es una canci√≥n.\n",
    "df[\"dance_valence\"] = df[\"danceability\"] * df[\"valence\"]\n",
    "\n",
    "new_features = [\n",
    "    \"duration_min\", \"beat_density\", \"energy_valence\", \"dance_energy\",\n",
    "        \"speech_valence\", \"acoustic_energy\", \"inst_energy\", \"dance_valence\"\n",
    "]\n",
    "\n",
    "print(\"Nuevas caracter√≠sticas creadas:\")\n",
    "for feature in new_features:\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "display(df[new_features].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073a0b7",
   "metadata": {},
   "source": [
    "### Actualizacion del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4e98f53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Archivo actualizado en: ../data/processed/spotify_clean_modeling.csv\n"
     ]
    }
   ],
   "source": [
    "## Update del Data Set para el Modelo\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "df.to_csv(\"../data/processed/spotify_clean_modeling.csv\", index=False)\n",
    "print(\"üíæ Archivo actualizado en: ../data/processed/spotify_clean_modeling.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105285d",
   "metadata": {},
   "source": [
    "### Columnas finales para training ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "85fa240e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genre', 'popularity', 'acousticness', 'danceability', 'energy',\n",
       "       'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo',\n",
       "       'valence', 'is_hit', 'duration_min', 'beat_density', 'energy_valence',\n",
       "       'dance_energy', 'speech_valence', 'acoustic_energy', 'inst_energy',\n",
       "       'dance_valence'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.columns.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"‚úÖ Canciones clasificadas como HIT: {df['is_hit'].sum()} de {len(df)} ({df['is_hit'].mean()*100:.2f}%)\")\n",
    "# Correlaci√≥n directa con popularidad o is_hit\n",
    "corr = df.corr(numeric_only=True)\n",
    "corr[\"is_hit\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704c99c6",
   "metadata": {},
   "source": [
    "Se encuentra un desbalance de los datos solo 9.6% representan hits, lo que nos hace notar que solo tener un buen accuracy (Predicciones Correctas) no\n",
    "es suficiente, para el modelo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12bf34",
   "metadata": {},
   "source": [
    "## Separaci√≥n de variables predictoras (X) y objetivo (y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68742ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=[\"is_hit\",\"popularity\"])\n",
    "y = df[\"is_hit\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c8b52",
   "metadata": {},
   "source": [
    "## Creaci√≥n de DataFrames para Codificar Variabls Categ√≥ricas y Entrenamiento de Modelos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para modelos de √°rboles ‚Üí LabelEncoder\n",
    "X_tree = X.copy()\n",
    "le = LabelEncoder()\n",
    "X_tree[\"genre\"] = le.fit_transform(X_tree[\"genre\"])\n",
    "\n",
    "# Para modelos lineales / distancia ‚Üí OneHotEncoder\n",
    "preprocessor_ohe = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"genre\"])\n",
    "], remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_tree.dtypes)\n",
    "X_tree.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52185733",
   "metadata": {},
   "source": [
    "## Division de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0daafb",
   "metadata": {},
   "source": [
    "### Divisi√≥n en entrenamiento y prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70705a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tree, X_test_tree, y_train, y_test = train_test_split(X_tree, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a713cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tree.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tree[\"genre\"].unique()[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1358b59",
   "metadata": {},
   "source": [
    "## Definici√≥n de Modelos Dinamico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381ba2ad",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression\n",
    "- Modelo lineal.  \n",
    "- Sirve como baseline.  \n",
    "- R√°pido, interpretable y muestra qu√© variables empujan a la probabilidad de ser hit.\n",
    "\n",
    "### 2. Random Forest\n",
    "- Ensamble de muchos √°rboles de decisi√≥n.  \n",
    "- Robusto, maneja no-linealidades y detecta interacciones entre features autom√°ticamente.\n",
    "\n",
    "### 3. Gradient Boosting (GBM cl√°sico de sklearn)\n",
    "- Construye √°rboles de manera secuencial, corrigiendo errores del anterior.  \n",
    "- Mejor rendimiento que RandomForest pero m√°s lento.\n",
    "\n",
    "### 4. XGBoost\n",
    "- Implementaci√≥n optimizada y m√°s poderosa de boosting.  \n",
    "- Alta precisi√≥n, muy usado en competencias de Kaggle.  \n",
    "- Excelente con datasets tabulares.\n",
    "\n",
    "### 5. LightGBM\n",
    "- Boosting muy r√°pido desarrollado por Microsoft.  \n",
    "- Funciona excelente con grandes vol√∫menes (como tu dataset de 230k filas).  \n",
    "- Suele superar a XGBoost en velocidad con rendimiento similar o mejor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CONFIGURACI√ìN GENERAL\n",
    "\n",
    "\n",
    "# Calcular peso de clase positiva (para XGBoost)\n",
    "pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# Colecci√≥n para guardar resultados de todos los experimentos\n",
    "resultados_globales = []\n",
    "\n",
    "\n",
    "# DEFINIR BATCHES PARA LOS MODELOS CON LOS HIPERPAR√ÅMETROS\n",
    "\n",
    "batch_1 = {\n",
    "    \"RandomForest\": {\"n_estimators\": 300, \"max_depth\": None, \"min_samples_leaf\": 2},\n",
    "    \"GradientBoosting\": {\"n_estimators\": 400, \"learning_rate\": 0.05, \"max_depth\": 5},\n",
    "    \"XGBoost\": {\"n_estimators\": 600, \"learning_rate\": 0.05, \"max_depth\": 6},\n",
    "    \"LightGBM\": {\"n_estimators\": 600, \"num_leaves\": 64, \"learning_rate\": 0.03},\n",
    "    \"LogisticRegression\": {\"max_iter\": 1000, \"solver\": \"liblinear\"},\n",
    "    \"KNeighbors\": {\"n_neighbors\": 10, \"weights\": \"distance\"}\n",
    "}\n",
    "\n",
    "batch_2 = {\n",
    "    \"RandomForest\": {\"n_estimators\": 800, \"max_depth\": 10, \"min_samples_leaf\": 1},\n",
    "    \"GradientBoosting\": {\"n_estimators\": 800, \"learning_rate\": 0.02, \"max_depth\": 6},\n",
    "    \"XGBoost\": {\"n_estimators\": 1000, \"learning_rate\": 0.03, \"max_depth\": 8},\n",
    "    \"LightGBM\": {\"n_estimators\": 1000, \"num_leaves\": 128, \"learning_rate\": 0.02},\n",
    "    \"LogisticRegression\": {\"max_iter\": 2000, \"solver\": \"liblinear\"},\n",
    "    \"KNeighbors\": {\"n_neighbors\": 20, \"weights\": \"uniform\"}\n",
    "}\n",
    "\n",
    "# Puedes agregar batch_3, batch_4, etc.\n",
    "batches = {\"Batch_1\": batch_1, \"Batch_2\": batch_2}\n",
    "\n",
    "\n",
    "# FUNCI√ìN PARA EJECUTAR UN BATCH\n",
    "def entrenar_batch(nombre_batch, config_batch):\n",
    "    resultados = []\n",
    "\n",
    "    # Modelos tipo √°rbol\n",
    "    tree_models = {\n",
    "        \"RandomForest\": RandomForestClassifier(n_jobs=-1, random_state=42, class_weight=\"balanced\", **config_batch[\"RandomForest\"]),\n",
    "        \"GradientBoosting\": GradientBoostingClassifier(random_state=42, **config_batch[\"GradientBoosting\"]),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            n_jobs=-1,\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42,\n",
    "            scale_pos_weight=pos_weight,\n",
    "            **config_batch[\"XGBoost\"]\n",
    "        ),\n",
    "        \"LightGBM\": LGBMClassifier(\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced\",\n",
    "            **config_batch[\"LightGBM\"]\n",
    "        )\n",
    "    }\n",
    "\n",
    "    for nombre, modelo in tree_models.items():\n",
    "        modelo.fit(X_train_tree, y_train)\n",
    "        y_pred = modelo.predict(X_test_tree)\n",
    "        resultados.append({\n",
    "            \"Batch\": nombre_batch,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"F1\": f1_score(y_test, y_pred),\n",
    "            \"ROC_AUC\": roc_auc_score(y_test, y_pred)\n",
    "        })\n",
    "\n",
    "    # Modelos lineales / distancia\n",
    "    linear_models = {\n",
    "        \"LogisticRegression\": LogisticRegression(class_weight=\"balanced\", **config_batch[\"LogisticRegression\"]),\n",
    "        \"KNeighbors\": KNeighborsClassifier(n_jobs=-1, **config_batch[\"KNeighbors\"])\n",
    "    }\n",
    "\n",
    "    for nombre, modelo in linear_models.items():\n",
    "        clf = Pipeline(steps=[\n",
    "            (\"preprocess\", preprocessor_ohe),\n",
    "            (\"model\", modelo)\n",
    "        ])\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        resultados.append({\n",
    "            \"Batch\": nombre_batch,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"F1\": f1_score(y_test, y_pred),\n",
    "            \"ROC_AUC\": roc_auc_score(y_test, y_pred)\n",
    "        })\n",
    "\n",
    "    return resultados\n",
    "\n",
    "\n",
    "# EJECUTAR TODOS LOS BATCHES\n",
    "\n",
    "\n",
    "for nombre_batch, config in batches.items():\n",
    "    resultados_globales.extend(entrenar_batch(nombre_batch, config))\n",
    "\n",
    "\n",
    "# RESULTADOS COMBINADOS\n",
    "\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados_globales).sort_values(by=[\"Batch\", \"F1\"], ascending=[True, False])\n",
    "display(df_resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b0074",
   "metadata": {},
   "source": [
    "## Tabla de resultados ordenada por Modelo y Accuracy para cada batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72001e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ordenado = (\n",
    "    df_resultados\n",
    "        .sort_values(by=[\"Modelo\", \"Accuracy\"], ascending=[True, False])\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "display(df_ordenado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94640cc0",
   "metadata": {},
   "source": [
    "# Interpretacion de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504788f2",
   "metadata": {},
   "source": [
    "## Resumen de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4b335",
   "metadata": {},
   "source": [
    "## 1. GradientBoosting (Batch_2)\n",
    "**Accuracy:** 0.916  \n",
    "**F1:** **0.394**  \n",
    "**ROC-AUC:** 0.632  \n",
    "\n",
    "**Interpretaci√≥n:**  \n",
    "- Accuracy alto, pero enga√±oso por el desbalance.  \n",
    "- F1 muy bajo ‚Üí **no detecta hits correctamente**.  \n",
    "- AUC ‚âà 0.63 ‚Üí pobre capacidad para separar HIT y NO HIT.  \n",
    "\n",
    "üëâ **Conclusi√≥n:** GradientBoosting **no es adecuado** para este problema.\n",
    "\n",
    "## 2. KNeighbors (Batch_2)\n",
    "**Accuracy:** 0.909  \n",
    "**F1:** **0.355**  \n",
    "**ROC-AUC:** 0.618  \n",
    "\n",
    "**Interpretaci√≥n:**  \n",
    "- Accuracy aceptable, pero no refleja buen rendimiento real.  \n",
    "- F1 muy bajo ‚Üí **fracasa detectando hits**.  \n",
    "- AUC ‚âà 0.62 ‚Üí apenas mejor que un modelo aleatorio.  \n",
    "\n",
    "üëâ **Conclusi√≥n:** KNN **es muy d√©bil** para este dataset.\n",
    "\n",
    "## 3. LightGBM (Batch_2)\n",
    "**Accuracy:** 0.872  \n",
    "**F1:** **0.569**  \n",
    "**ROC-AUC:** **0.869**  \n",
    "\n",
    "**Interpretaci√≥n:**  \n",
    "- Accuracy moderado porque arriesga m√°s (bueno para HIT).  \n",
    "- F1 alto ‚Üí **mejor balance entre precisi√≥n y recall**.  \n",
    "- AUC ‚âà 0.87 ‚Üí muy buena capacidad de separabilidad.  \n",
    "\n",
    "üëâ **Conclusi√≥n:** LightGBM es **el mejor modelo del batch 2**.\n",
    "\n",
    "## 4. Logistic Regression (Batch_2)\n",
    "**Accuracy:** 0.756  \n",
    "**F1:** **0.415**  \n",
    "**ROC-AUC:** 0.805  \n",
    "\n",
    "**Interpretaci√≥n:**  \n",
    "- Accuracy bajo, pero normal para un modelo simple.  \n",
    "- F1 razonable para un baseline.  \n",
    "- AUC ‚âà 0.80 ‚Üí separaci√≥n aceptable.  \n",
    "\n",
    "üëâ **Conclusi√≥n:** Modelo decente como referencia inicial.\n",
    "\n",
    "## 5. RandomForest (Batch_2)\n",
    "**Accuracy:** 0.926  \n",
    "**F1:** **0.449**  \n",
    "**ROC-AUC:** 0.676  \n",
    "\n",
    "**Interpretaci√≥n:**  \n",
    "- Accuracy muy alto, pero enga√±oso por la clase dominante.  \n",
    "- F1 mediocre ‚Üí **predice casi siempre NO HIT**.  \n",
    "- AUC ‚âà 0.67 ‚Üí pobre capacidad para distinguir clases.  \n",
    "\n",
    "üëâ **Conclusi√≥n:** RandomForest **no es buena opci√≥n** para este problema.\n",
    "\n",
    "## 6. XGBoost (Batch_2)\n",
    "**Accuracy:** 0.872  \n",
    "**F1:** **0.567**  \n",
    "**ROC-AUC:** **0.866**  \n",
    "\n",
    "**Interpretaci√≥n:**  \n",
    "- Accuracy similar a LightGBM.  \n",
    "- F1 muy alto ‚Üí **excelente detecci√≥n de hits**.  \n",
    "- AUC ‚âà 0.86 ‚Üí fuerte separabilidad HIT/NO HIT.  \n",
    "\n",
    "üëâ **Conclusi√≥n:** XGBoost es **el segundo mejor modelo**, casi empatado con LightGBM.\n",
    "\n",
    "# üèÜ Conclusi√≥n General del Batch 2\n",
    "\n",
    "| Modelo | Resultado |\n",
    "|--|--|\n",
    "| **ü•á LightGBM** | Mejor F1 y mejor AUC |\n",
    "| **ü•à XGBoost** | Excelente rendimiento, muy cercano a LightGBM |\n",
    "| Logistic Regression | Baseline aceptable |\n",
    "| RandomForest | No apto (sesgo hacia clase NO HIT) |\n",
    "| GradientBoosting | Muy bajo desempe√±o |\n",
    "| KNeighbors | Inadecuado para este tipo de datos |\n",
    "\n",
    "**LightGBM y XGBoost son los modelos recomendados para avanzar al entrenamiento final.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch1 = df_resultados[df_resultados[\"Batch\"] == \"Batch_1\"]\n",
    "df_batch1.plot(\n",
    "    x=\"Modelo\",\n",
    "    y=[\"Accuracy\", \"F1\", \"ROC_AUC\"],\n",
    "    kind=\"bar\",\n",
    "    figsize=(10,5)\n",
    ")\n",
    "plt.title(\"Comparaci√≥n de modelos ‚Äì Predicci√≥n de 'Hit' (Batch 1)\")\n",
    "plt.ylabel(\"Puntaje\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8384e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch2 = df_resultados[df_resultados[\"Batch\"] == \"Batch_2\"]\n",
    "df_batch2.plot(\n",
    "    x=\"Modelo\",\n",
    "    y=[\"Accuracy\", \"F1\", \"ROC_AUC\"],\n",
    "    kind=\"bar\",\n",
    "    figsize=(10,5)\n",
    ")\n",
    "plt.title(\"Comparaci√≥n de modelos ‚Äì Predicci√≥n de 'Hit' (Batch 2)\")\n",
    "plt.ylabel(\"Puntaje\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf6a60",
   "metadata": {},
   "source": [
    "## Comparacion de F1-Score Bacth1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=df_resultados, x=\"Modelo\", y=\"F1\", hue=\"Batch\")\n",
    "plt.title(\"Comparaci√≥n de F1-score por modelo y batch\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=df_resultados, x=\"Modelo\", y=\"ROC_AUC\", hue=\"Batch\")\n",
    "plt.title(\"Comparaci√≥n de ROC_AUC por modelo y batch\")\n",
    "plt.ylabel(\"ROC_AUC\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa58e8d",
   "metadata": {},
   "source": [
    "## Seleccion de Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f1760",
   "metadata": {},
   "source": [
    "1. Mejor F1-score del Batch 2\n",
    "\n",
    "El F1 es la m√©trica m√°s importante porque el dataset est√° fuertemente desbalanceado (~4‚Äì5% hits).\n",
    "\n",
    "Batch 2 ‚Äî LightGBM:\n",
    "\n",
    "F1 = 0.5690 (el m√°s alto de todos los modelos)\n",
    "\n",
    "Esto significa que LightGBM:\n",
    "\n",
    "Detecta muchos m√°s hits que otros modelos\n",
    "\n",
    "Maneja mejor el desbalance\n",
    "\n",
    "Tiene la mejor combinaci√≥n de precision + recall para la clase HIT\n",
    "\n",
    "Comparaciones:\n",
    "\n",
    "Modelo\tF1 (Batch_2)\n",
    "LightGBM\t0.569\n",
    "XGBoost\t0.567\n",
    "RandomForest\t0.449\n",
    "LogisticRegression\t0.415\n",
    "GradientBoosting\t0.394\n",
    "KNN\t0.355\n",
    "\n",
    "üü¢ LightGBM gana el F1-score del Batch 2.\n",
    "\n",
    "2. AUC muy alto (segundo mejor pero casi empatado)\n",
    "\n",
    "Batch 2:\n",
    "\n",
    "LightGBM AUC = 0.8690\n",
    "\n",
    "Esto indica:\n",
    "\n",
    "Excelente capacidad para separar HIT vs NO HIT\n",
    "\n",
    "Umbral de decisi√≥n m√°s estable\n",
    "\n",
    "Curva ROC muy s√≥lida\n",
    "\n",
    "Comparaci√≥n:\n",
    "\n",
    "Modelo\tAUC (Batch_2)\n",
    "LightGBM\t0.869\n",
    "XGBoost\t0.866\n",
    "LogisticRegression\t0.805\n",
    "RandomForest\t0.676\n",
    "GradientBoosting\t0.632\n",
    "KNN\t0.618\n",
    "\n",
    "üü¢ LightGBM tiene el mejor AUC del batch (empatado virtualmente con XGBoost)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
